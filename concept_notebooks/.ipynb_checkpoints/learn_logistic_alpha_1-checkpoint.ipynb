{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1002\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1002\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\": \"T2yuo9Oe71Cz/I4X9Ac5+gpEa5a8PpJCDlqKYO0CfAuEszu1JrXLl8YugMqYe3sM\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\": \"98GDGJ0kOMCUMUePhksaQ/GYgB3+NH9h996V88sh3aOiUNX3N+fLXAtry6xctSZ6\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\": \"89bArO+nlbP3sgakeHjCo1JYxYR5wufVgA3IbUvDY+K7w4zyxJqssu7wVnfeKCq8\"};\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      if (url in hashes) {\n",
       "        element.crossOrigin = \"anonymous\";\n",
       "        element.integrity = \"sha384-\" + hashes[url];\n",
       "      }\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1002\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\": \"T2yuo9Oe71Cz/I4X9Ac5+gpEa5a8PpJCDlqKYO0CfAuEszu1JrXLl8YugMqYe3sM\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\": \"98GDGJ0kOMCUMUePhksaQ/GYgB3+NH9h996V88sh3aOiUNX3N+fLXAtry6xctSZ6\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\": \"89bArO+nlbP3sgakeHjCo1JYxYR5wufVgA3IbUvDY+K7w4zyxJqssu7wVnfeKCq8\"};\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import logging\n",
    "import logging.config\n",
    "import json\n",
    "import shutil\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "\n",
    "# mpl.use('Agg')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "import sqlite3\n",
    "import git\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from misc.database import Database\n",
    "\n",
    "from prediction_model import utils\n",
    "from prediction_model.models.lstm_l0 import L0SeqLSTM\n",
    "from prediction_model.models.fully_connected_l0 import L0FCN\n",
    "from prediction_model.models.ntm_aio_l0 import EncapsulatedNTML0\n",
    "from prediction_model.models.ntm_aio import EncapsulatedNTM\n",
    "from prediction_model.objectives.sse import SSE\n",
    "from prediction_model.objectives.logistic_loss import LogisticLoss\n",
    "\n",
    "# plotting tools\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models import CustomJS, Slider, ColumnDataSource, Whisker\n",
    "\n",
    "from datetime import datetime\n",
    "from types import SimpleNamespace\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_forward_fcn(X_train, y_train, model_p, objective_p, optimizer_p, l0_reg, backward=True, enable_gpu=False):\n",
    "    model_out = []\n",
    "    total_log_loss = None\n",
    "    total_penalty = None\n",
    "    \n",
    "    X_train = torch.FloatTensor(X_train)\n",
    "    y_train = torch.FloatTensor(y_train)\n",
    "    if enable_gpu:\n",
    "        X_train = X_train.cuda()\n",
    "        y_train = y_train.cuda()\n",
    "\n",
    "    out, (hidden, penalty) = model_p.forward(X_train)\n",
    "#         ht, ct = hidden\n",
    "    # print(x_t1, out)\n",
    "    out = torch.clamp(out, -8, 8)\n",
    "    out = F.sigmoid(out)\n",
    "    # print(out)\n",
    "\n",
    "#     print(out.shape)\n",
    "#     print(y_train.shape)\n",
    "    log_loss = objective_p(out, y_train)\n",
    "\n",
    "    if total_log_loss is None:\n",
    "        total_log_loss = log_loss\n",
    "        total_penalty = penalty\n",
    "    else:\n",
    "        total_log_loss += log_loss\n",
    "        total_penalty += penalty\n",
    "\n",
    "    model_out.append(out.cpu().data.numpy())\n",
    "\n",
    "    total_loss = total_log_loss + l0_reg * total_penalty\n",
    "\n",
    "    if backward:\n",
    "        model.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer_p.step()\n",
    "\n",
    "    if backward:\n",
    "        total_penalty = np.sum(total_penalty.cpu().data.numpy())\n",
    "\n",
    "    return model, \\\n",
    "           (np.sum(total_log_loss.cpu().data.numpy()), total_penalty), \\\n",
    "           model_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_map(x, alpha):\n",
    "    return alpha*x*(1-x)\n",
    "\n",
    "def linear_map(x, alpha):\n",
    "    return alpha*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc0\n",
      "Gate mode: unique\n",
      "fc1\n",
      "Gate mode: unique\n",
      "Gate mode: unique\n",
      "\n",
      "epoch: 0 SSE loss: 0.10524124145507813, l0 penalty: 8.002297973632812 total loss: 5.662176971435547\n",
      "accuracy: 0.0, actual: [0.5488135  0.71518937 0.60276338 0.54488318 0.4236548  0.64589411\n",
      " 0.43758721 0.891773   0.96366276 0.38344152 0.79172504 0.52889492\n",
      " 0.56804456 0.92559664 0.07103606 0.0871293  0.0202184  0.83261985\n",
      " 0.77815675 0.87001215 0.97861834 0.79915856 0.46147936 0.78052918\n",
      " 0.11827443 0.63992102 0.14335329 0.94466892 0.52184832 0.41466194\n",
      " 0.26455561 0.77423369 0.45615033 0.56843395 0.0187898  0.6176355\n",
      " 0.61209572 0.616934   0.94374808 0.6818203  0.3595079  0.43703195\n",
      " 0.6976312  0.06022547 0.66676672 0.67063787 0.21038256 0.1289263\n",
      " 0.31542835 0.36371077], predicted: [0.4910428  0.49057236 0.4908599  0.49105614 0.49139714 0.49071363\n",
      " 0.4913607  0.49023575 0.49009866 0.49150643 0.49042645 0.4911103\n",
      " 0.49097762 0.49017122 0.49235564 0.49231192 0.49249384 0.49034846\n",
      " 0.49045232 0.49027723 0.49007136 0.4904123  0.49129826 0.49044785\n",
      " 0.49222726 0.49073395 0.49215913 0.49013487 0.49113423 0.4914216\n",
      " 0.49182957 0.49045977 0.49131218 0.49097624 0.4924977  0.49080947\n",
      " 0.49082825 0.49081182 0.49013662 0.49063602 0.49157146 0.49136218\n",
      " 0.49060583 0.49238503 0.49066472 0.49065736 0.49197686 0.49219826\n",
      " 0.49169132 0.49156004], n_params: 481 model_out: [0.4910428  0.49057236 0.4908599  0.49105614 0.49139714 0.49071363\n",
      " 0.4913607  0.49023575 0.49009866 0.49150643 0.49042645 0.4911103\n",
      " 0.49097762 0.49017122 0.49235564 0.49231192 0.49249384 0.49034846\n",
      " 0.49045232 0.49027723 0.49007136 0.4904123  0.49129826 0.49044785\n",
      " 0.49222726 0.49073395 0.49215913 0.49013487 0.49113423 0.4914216\n",
      " 0.49182957 0.49045977 0.49131218 0.49097624 0.4924977  0.49080947\n",
      " 0.49082825 0.49081182 0.49013662 0.49063602 0.49157146 0.49136218\n",
      " 0.49060583 0.49238503 0.49066472 0.49065736 0.49197686 0.49219826\n",
      " 0.49169132 0.49156004]\n",
      "\n",
      "epoch: 100 SSE loss: 0.09576944351196288, l0 penalty: 7.995267944335938 total loss: 5.188235572814941\n",
      "accuracy: 0.0, actual: [0.36678022 0.29762418 0.06859959 0.35252753 0.23219605 0.76292734\n",
      " 0.1116283  0.14368104 0.2785103  0.28802683 0.84630494 0.79128366\n",
      " 0.57863563 0.28858868 0.31887835 0.59221827 0.73986656 0.38409806\n",
      " 0.50956203 0.88803314 0.64979086 0.53555013 0.07122246 0.17601521\n",
      " 0.20099158 0.62314829 0.10811275 0.02899487 0.36035056 0.71885918\n",
      " 0.69324935 0.79267035 0.69624826 0.61328558 0.4861621  0.20849832\n",
      " 0.56854806 0.63662475 0.12374333 0.56514734 0.09774871 0.5470768\n",
      " 0.15891889 0.11901355 0.11310006 0.91102531 0.59808732 0.25015872\n",
      " 0.07144888 0.53618142], predicted: [0.48829487 0.4885336  0.4891837  0.48834404 0.48874784 0.48713213\n",
      " 0.48906904 0.48898363 0.4885996  0.48856676 0.4869691  0.48707667\n",
      " 0.4875714  0.48856482 0.48846024 0.48752847 0.48717728 0.48823515\n",
      " 0.487802   0.48688748 0.48735344 0.48771226 0.48917672 0.4888975\n",
      " 0.48883095 0.48743203 0.4890784  0.4892892  0.4883171  0.48721835\n",
      " 0.4872684  0.48707396 0.48726258 0.48746276 0.48788273 0.48881096\n",
      " 0.48760352 0.48739    0.48903677 0.4876144  0.489106   0.48767245\n",
      " 0.48894304 0.48904938 0.48906517 0.4868425  0.48751011 0.4886975\n",
      " 0.4891761  0.48771006], n_params: 481 model_out: [0.48829487 0.4885336  0.4891837  0.48834404 0.48874784 0.48713213\n",
      " 0.48906904 0.48898363 0.4885996  0.48856676 0.4869691  0.48707667\n",
      " 0.4875714  0.48856482 0.48846024 0.48752847 0.48717728 0.48823515\n",
      " 0.487802   0.48688748 0.48735344 0.48771226 0.48917672 0.4888975\n",
      " 0.48883095 0.48743203 0.4890784  0.4892892  0.4883171  0.48721835\n",
      " 0.4872684  0.48707396 0.48726258 0.48746276 0.48788273 0.48881096\n",
      " 0.48760352 0.48739    0.48903677 0.4876144  0.489106   0.48767245\n",
      " 0.48894304 0.48904938 0.48906517 0.4868425  0.48751011 0.4886975\n",
      " 0.4891761  0.48771006]\n",
      "\n",
      "epoch: 200 SSE loss: 0.12182861328125, l0 penalty: 7.988851928710938 total loss: 6.490873260498047\n",
      "accuracy: 0.0, actual: [0.74826798 0.18020271 0.38902314 0.03760018 0.01178774 0.99626787\n",
      " 0.48819666 0.37202476 0.19617209 0.80719225 0.70575272 0.0015562\n",
      " 0.77122667 0.11148275 0.94863268 0.33273608 0.45110278 0.00498091\n",
      " 0.82439269 0.30816825 0.55644688 0.9266008  0.15622238 0.86732961\n",
      " 0.50023893 0.92445617 0.82235505 0.44298003 0.08871177 0.03019745\n",
      " 0.87423081 0.47428492 0.66369491 0.88164841 0.30465899 0.89576302\n",
      " 0.02753244 0.27992568 0.8117664  0.85322032 0.9448354  0.30301127\n",
      " 0.78023559 0.9851303  0.52700602 0.25259629 0.03896232 0.75965306\n",
      " 0.13884538 0.38694261], predicted: [0.4838635  0.485627   0.48489523 0.4861873  0.4862888  0.4834104\n",
      " 0.48456708 0.48495337 0.48556426 0.48374587 0.48394847 0.48632905\n",
      " 0.48381767 0.48589703 0.48346797 0.4850878  0.48468623 0.48631552\n",
      " 0.4837115  0.4851719  0.48434773 0.48350742 0.48572126 0.4836257\n",
      " 0.48452833 0.48351166 0.48371556 0.48471233 0.4859865  0.48621646\n",
      " 0.483612   0.48461175 0.48403358 0.48359716 0.48518392 0.48356897\n",
      " 0.48622695 0.4852686  0.48373672 0.48365393 0.48347253 0.48518962\n",
      " 0.48379967 0.48342383 0.48444232 0.48536208 0.48618203 0.4838408\n",
      " 0.48578954 0.48490235], n_params: 481 model_out: [0.4838635  0.485627   0.48489523 0.4861873  0.4862888  0.4834104\n",
      " 0.48456708 0.48495337 0.48556426 0.48374587 0.48394847 0.48632905\n",
      " 0.48381767 0.48589703 0.48346797 0.4850878  0.48468623 0.48631552\n",
      " 0.4837115  0.4851719  0.48434773 0.48350742 0.48572126 0.4836257\n",
      " 0.48452833 0.48351166 0.48371556 0.48471233 0.4859865  0.48621646\n",
      " 0.483612   0.48461175 0.48403358 0.48359716 0.48518392 0.48356897\n",
      " 0.48622695 0.4852686  0.48373672 0.48365393 0.48347253 0.48518962\n",
      " 0.48379967 0.48342383 0.48444232 0.48536208 0.48618203 0.4838408\n",
      " 0.48578954 0.48490235]\n",
      "\n",
      "epoch: 300 SSE loss: 0.09709875106811523, l0 penalty: 7.982630615234375 total loss: 5.25406908416748\n",
      "accuracy: 0.0, actual: [0.38613786 0.71247659 0.58098534 0.46313774 0.94364596 0.74239641\n",
      " 0.94446665 0.80260609 0.15405246 0.20687026 0.06607917 0.39675446\n",
      " 0.49393799 0.98976068 0.90401917 0.21254029 0.39854018 0.51468104\n",
      " 0.57275152 0.23703318 0.28854573 0.61574602 0.33767913 0.71972114\n",
      " 0.29835304 0.21042103 0.53764989 0.10600488 0.93471516 0.22275683\n",
      " 0.46161675 0.71566021 0.60435755 0.29129393 0.93588236 0.45631744\n",
      " 0.68130624 0.14505727 0.26229578 0.16338432 0.61311318 0.07904725\n",
      " 0.42231007 0.40815435 0.18240378 0.18156717 0.32826971 0.51764318\n",
      " 0.61310538 0.70781868], predicted: [0.48138803 0.48043266 0.48075464 0.4811377  0.48009682 0.48037103\n",
      " 0.48009577 0.4802776  0.48227763 0.48207155 0.4826208  0.4813535\n",
      " 0.48103756 0.48003775 0.48014754 0.48204938 0.48134768 0.48097014\n",
      " 0.48078138 0.4819539  0.4817529  0.48064166 0.48156124 0.4804177\n",
      " 0.48171467 0.4820577  0.4808955  0.48246503 0.48010826 0.48200956\n",
      " 0.48114267 0.48042607 0.48067868 0.4817422  0.48010677 0.4811599\n",
      " 0.4804968  0.48231268 0.48185533 0.4822412  0.48065025 0.4825703\n",
      " 0.48127043 0.48131642 0.48216698 0.4821703  0.48159796 0.48096055\n",
      " 0.48065025 0.48044223], n_params: 481 model_out: [0.48138803 0.48043266 0.48075464 0.4811377  0.48009682 0.48037103\n",
      " 0.48009577 0.4802776  0.48227763 0.48207155 0.4826208  0.4813535\n",
      " 0.48103756 0.48003775 0.48014754 0.48204938 0.48134768 0.48097014\n",
      " 0.48078138 0.4819539  0.4817529  0.48064166 0.48156124 0.4804177\n",
      " 0.48171467 0.4820577  0.4808955  0.48246503 0.48010826 0.48200956\n",
      " 0.48114267 0.48042607 0.48067868 0.4817422  0.48010677 0.4811599\n",
      " 0.4804968  0.48231268 0.48185533 0.4822412  0.48065025 0.4825703\n",
      " 0.48127043 0.48131642 0.48216698 0.4821703  0.48159796 0.48096055\n",
      " 0.48065025 0.48044223]\n",
      "\n",
      "epoch: 400 SSE loss: 0.11484070777893067, l0 penalty: 7.976580200195312 total loss: 6.140864398956299\n",
      "accuracy: 0.0, actual: [0.39217296 0.04115659 0.92330057 0.40623497 0.94428218 0.72272449\n",
      " 0.91831995 0.82326754 0.6468967  0.06793902 0.83881577 0.6928224\n",
      " 0.95799151 0.14222247 0.08777354 0.51887998 0.35993237 0.96027368\n",
      " 0.70377222 0.44599407 0.19220875 0.44288141 0.46628642 0.00914256\n",
      " 0.25721541 0.2453717  0.38102144 0.42403833 0.26753056 0.11264625\n",
      " 0.13867957 0.68820216 0.95588973 0.34485436 0.14278639 0.2600578\n",
      " 0.15217505 0.19473966 0.66216051 0.38492733 0.25045429 0.58115791\n",
      " 0.89782395 0.02442901 0.59671877 0.67199599 0.43316907 0.92035175\n",
      " 0.17018718 0.01158581], predicted: [0.47772264 0.47905362 0.47651786 0.47767058 0.47648922 0.47679335\n",
      " 0.47652462 0.4766547  0.47689793 0.4789511  0.47663325 0.47683463\n",
      " 0.47647056 0.47866663 0.4788752  0.4772537  0.477842   0.47646746\n",
      " 0.47681955 0.47752342 0.4784753  0.47753495 0.47744834 0.4791762\n",
      " 0.47822642 0.47827178 0.47776395 0.47760472 0.47818696 0.4787799\n",
      " 0.47868025 0.476841   0.47647342 0.4778978  0.47866458 0.47821552\n",
      " 0.47862858 0.4784656  0.47687688 0.47774947 0.47825226 0.47704053\n",
      " 0.47655267 0.4791177  0.4769903  0.47686335 0.47757095 0.4765219\n",
      " 0.47855958 0.4791669 ], n_params: 481 model_out: [0.47772264 0.47905362 0.47651786 0.47767058 0.47648922 0.47679335\n",
      " 0.47652462 0.4766547  0.47689793 0.4789511  0.47663325 0.47683463\n",
      " 0.47647056 0.47866663 0.4788752  0.4772537  0.477842   0.47646746\n",
      " 0.47681955 0.47752342 0.4784753  0.47753495 0.47744834 0.4791762\n",
      " 0.47822642 0.47827178 0.47776395 0.47760472 0.47818696 0.4787799\n",
      " 0.47868025 0.476841   0.47647342 0.4778978  0.47866458 0.47821552\n",
      " 0.47862858 0.4784656  0.47687688 0.47774947 0.47825226 0.47704053\n",
      " 0.47655267 0.4791177  0.4769903  0.47686335 0.47757095 0.4765219\n",
      " 0.47855958 0.4791669 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 500 SSE loss: 0.08815521240234375, l0 penalty: 7.97047607421875 total loss: 4.806284423828125\n",
      "accuracy: 0.0, actual: [0.8812033  0.53122103 0.8680575  0.77755907 0.96932112 0.92571412\n",
      " 0.16927561 0.57996402 0.02856338 0.68828411 0.54150551 0.14278145\n",
      " 0.66640611 0.36708941 0.09459162 0.00299151 0.60631975 0.79011012\n",
      " 0.47399445 0.36391856 0.75603037 0.0063267  0.80624946 0.14631303\n",
      " 0.2934198  0.61383733 0.8059898  0.14708033 0.66029159 0.40847581\n",
      " 0.25638414 0.39374154 0.38463804 0.83570583 0.53699062 0.84165466\n",
      " 0.16601442 0.83759583 0.3109018  0.71662891 0.49894272 0.59874476\n",
      " 0.64255778 0.64013713 0.93336891 0.68057536 0.57611589 0.27045168\n",
      " 0.83392349 0.2913378 ], predicted: [0.47267935 0.4732891  0.4726977  0.4728248  0.47256207 0.47261703\n",
      " 0.47463748 0.47313565 0.4750991  0.4729502  0.47325674 0.47474164\n",
      " 0.47298092 0.4738727  0.47491825 0.47516906 0.47306532 0.4728071\n",
      " 0.47346926 0.47388488 0.47285497 0.4751599  0.47278446 0.47472772\n",
      " 0.4741549  0.47305474 0.47278482 0.4747247  0.4729895  0.4737142\n",
      " 0.47429672 0.47377068 0.47380555 0.4727431  0.47327092 0.47273475\n",
      " 0.47465038 0.47274044 0.4740879  0.47291037 0.4733907  0.47307658\n",
      " 0.4730144  0.47301784 0.47260723 0.47296098 0.4731478  0.4742428\n",
      " 0.4727456  0.47416282], n_params: 481 model_out: [0.47267935 0.4732891  0.4726977  0.4728248  0.47256207 0.47261703\n",
      " 0.47463748 0.47313565 0.4750991  0.4729502  0.47325674 0.47474164\n",
      " 0.47298092 0.4738727  0.47491825 0.47516906 0.47306532 0.4728071\n",
      " 0.47346926 0.47388488 0.47285497 0.4751599  0.47278446 0.47472772\n",
      " 0.4741549  0.47305474 0.47278482 0.4747247  0.4729895  0.4737142\n",
      " 0.47429672 0.47377068 0.47380555 0.4727431  0.47327092 0.47273475\n",
      " 0.47465038 0.47274044 0.4740879  0.47291037 0.4733907  0.47307658\n",
      " 0.4730144  0.47301784 0.47260723 0.47296098 0.4731478  0.4742428\n",
      " 0.4727456  0.47416282]\n",
      "\n",
      "epoch: 600 SSE loss: 0.10000570297241211, l0 penalty: 7.964530029296875 total loss: 5.3985116500854495\n",
      "accuracy: 0.0, actual: [0.75812542 0.50331851 0.17701666 0.83253651 0.51682478 0.92691954\n",
      " 0.97180655 0.67512985 0.31210011 0.57568377 0.37128647 0.26900403\n",
      " 0.45417978 0.41377712 0.61058927 0.85361765 0.34963372 0.44891199\n",
      " 0.83313308 0.19089717 0.12547063 0.54400476 0.83111422 0.37333347\n",
      " 0.63191116 0.00982364 0.90909502 0.60338692 0.25861527 0.07822874\n",
      " 0.22444552 0.6287925  0.66916877 0.71035704 0.84637976 0.53547476\n",
      " 0.24972678 0.97036749 0.11327181 0.29375873 0.71347302 0.60563551\n",
      " 0.54386465 0.11447021 0.97937719 0.14783995 0.33024472 0.38168559\n",
      " 0.23460727 0.29062888], predicted: [0.46884486 0.46938518 0.47046545 0.46872872 0.46934116 0.468581\n",
      " 0.46851075 0.46897423 0.47003618 0.46914944 0.46981525 0.47020492\n",
      " 0.46954525 0.46967685 0.46907485 0.46869576 0.46988916 0.46956238\n",
      " 0.46872783 0.47042698 0.47060847 0.46925265 0.46873096 0.46980858\n",
      " 0.4690416  0.4709293  0.46860895 0.46908608 0.4702432  0.4707395\n",
      " 0.47033504 0.46904647 0.46898353 0.4689193  0.46870708 0.46928048\n",
      " 0.47026706 0.46851304 0.4706423  0.470108   0.46891448 0.4690826\n",
      " 0.46925312 0.470639   0.46849892 0.47054642 0.4699651  0.46978137\n",
      " 0.47030774 0.47012028], n_params: 481 model_out: [0.46884486 0.46938518 0.47046545 0.46872872 0.46934116 0.468581\n",
      " 0.46851075 0.46897423 0.47003618 0.46914944 0.46981525 0.47020492\n",
      " 0.46954525 0.46967685 0.46907485 0.46869576 0.46988916 0.46956238\n",
      " 0.46872783 0.47042698 0.47060847 0.46925265 0.46873096 0.46980858\n",
      " 0.4690416  0.4709293  0.46860895 0.46908608 0.4702432  0.4707395\n",
      " 0.47033504 0.46904647 0.46898353 0.4689193  0.46870708 0.46928048\n",
      " 0.47026706 0.46851304 0.4706423  0.470108   0.46891448 0.4690826\n",
      " 0.46925312 0.470639   0.46849892 0.47054642 0.4699651  0.46978137\n",
      " 0.47030774 0.47012028]\n",
      "\n",
      "epoch: 700 SSE loss: 0.09049676895141602, l0 penalty: 7.958580322265625 total loss: 4.922767463684082\n",
      "accuracy: 0.0, actual: [0.7909194  0.28250144 0.02779646 0.14549716 0.64926301 0.73753445\n",
      " 0.88764523 0.54307337 0.74289222 0.87187923 0.42047188 0.85915921\n",
      " 0.57191535 0.90348303 0.13921117 0.35376689 0.42749002 0.63456637\n",
      " 0.05837095 0.61346231 0.26880183 0.81792497 0.44562014 0.6465115\n",
      " 0.91640023 0.86853964 0.65251989 0.8583095  0.75278152 0.53853656\n",
      " 0.55966793 0.49858324 0.79826925 0.77134181 0.43181075 0.9815793\n",
      " 0.88579452 0.19671698 0.30000431 0.85106393 0.12575257 0.33814935\n",
      " 0.62804964 0.8728835  0.41265963 0.78409081 0.39774506 0.47079903\n",
      " 0.40723483 0.78952942], predicted: [0.46453992 0.4656902  0.4663381  0.46601483 0.46477908 0.46463028\n",
      " 0.46437606 0.4650123  0.46462122 0.4644028  0.4654074  0.46442428\n",
      " 0.4649163  0.4643492  0.46603212 0.46554413 0.46539298 0.46480364\n",
      " 0.46625412 0.46483892 0.46571824 0.46449414 0.4653366  0.46478373\n",
      " 0.46432742 0.46440846 0.46477363 0.46442574 0.46460444 0.46502736\n",
      " 0.46495703 0.4651603  0.46452746 0.46457306 0.4653826  0.46421704\n",
      " 0.4643792  0.46587506 0.4656543  0.46443802 0.4660691  0.46557605\n",
      " 0.4648145  0.46440104 0.4654234  0.46455145 0.46545398 0.4652528\n",
      " 0.4654345  0.46454224], n_params: 481 model_out: [0.46453992 0.4656902  0.4663381  0.46601483 0.46477908 0.46463028\n",
      " 0.46437606 0.4650123  0.46462122 0.4644028  0.4654074  0.46442428\n",
      " 0.4649163  0.4643492  0.46603212 0.46554413 0.46539298 0.46480364\n",
      " 0.46625412 0.46483892 0.46571824 0.46449414 0.4653366  0.46478373\n",
      " 0.46432742 0.46440846 0.46477363 0.46442574 0.46460444 0.46502736\n",
      " 0.46495703 0.4651603  0.46452746 0.46457306 0.4653826  0.46421704\n",
      " 0.4643792  0.46587506 0.4656543  0.46443802 0.4660691  0.46557605\n",
      " 0.4648145  0.46440104 0.4654234  0.46455145 0.46545398 0.4652528\n",
      " 0.4654345  0.46454224]\n",
      "\n",
      "epoch: 800 SSE loss: 0.09468379974365235, l0 penalty: 7.9526611328125 total loss: 5.131823043823243\n",
      "accuracy: 0.0, actual: [0.36925632 0.211326   0.47690477 0.08223436 0.23765937 0.08349778\n",
      " 0.37775196 0.23115434 0.89923405 0.17243879 0.58606063 0.0293196\n",
      " 0.22116391 0.76042999 0.25812895 0.13981352 0.12554288 0.47101992\n",
      " 0.39563897 0.65328823 0.56019416 0.07816924 0.02716346 0.50599998\n",
      " 0.90595654 0.30281482 0.60656058 0.87193057 0.94129594 0.04724934\n",
      " 0.21995757 0.16778754 0.99617849 0.65796821 0.31172048 0.47599878\n",
      " 0.33356434 0.08995792 0.76550651 0.25541545 0.48722409 0.59632105\n",
      " 0.80354331 0.66744234 0.51242426 0.1437468  0.39902569 0.11828575\n",
      " 0.10872713 0.52165183], predicted: [0.4605366  0.46088594 0.46029744 0.46119547 0.46082765 0.4611919\n",
      " 0.4605178  0.46084207 0.4594899  0.460972   0.4600744  0.46134722\n",
      " 0.46086416 0.4597623  0.4607824  0.46104482 0.46107686 0.46031085\n",
      " 0.46047822 0.45997256 0.4601078  0.46120715 0.46135336 0.46023118\n",
      " 0.45947674 0.46068355 0.46005017 0.4595435  0.4594074  0.46129575\n",
      " 0.46086684 0.46098223 0.45930254 0.45996338 0.46066388 0.46029946\n",
      " 0.46061552 0.46117333 0.45975232 0.46078843 0.46027392 0.46006227\n",
      " 0.45967767 0.4599448  0.46021655 0.46103594 0.46047074 0.46109313\n",
      " 0.46111956 0.46019554], n_params: 481 model_out: [0.4605366  0.46088594 0.46029744 0.46119547 0.46082765 0.4611919\n",
      " 0.4605178  0.46084207 0.4594899  0.460972   0.4600744  0.46134722\n",
      " 0.46086416 0.4597623  0.4607824  0.46104482 0.46107686 0.46031085\n",
      " 0.46047822 0.45997256 0.4601078  0.46120715 0.46135336 0.46023118\n",
      " 0.45947674 0.46068355 0.46005017 0.4595435  0.4594074  0.46129575\n",
      " 0.46086684 0.46098223 0.45930254 0.45996338 0.46066388 0.46029946\n",
      " 0.46061552 0.46117333 0.45975232 0.46078843 0.46027392 0.46006227\n",
      " 0.45967767 0.4599448  0.46021655 0.46103594 0.46047074 0.46109313\n",
      " 0.46111956 0.46019554]\n",
      "\n",
      "epoch: 900 SSE loss: 0.0692207670211792, l0 penalty: 7.946847534179687 total loss: 3.8583807277679445\n",
      "accuracy: 0.0, actual: [5.03662376e-01 5.62413438e-04 8.49366382e-01 6.40582173e-01\n",
      " 4.97825606e-02 8.36452273e-01 3.74011890e-01 4.88103694e-01\n",
      " 6.25784263e-01 2.53952752e-01 7.51722027e-01 4.72490944e-01\n",
      " 4.88663128e-01 1.83974281e-01 4.03368504e-01 6.04430227e-01\n",
      " 2.91091209e-01 2.21289553e-01 1.30716193e-01 8.24653229e-01\n",
      " 2.39531431e-01 4.70794721e-01 2.20222329e-01 9.31364097e-01\n",
      " 4.90760213e-01 8.75351224e-01 9.62423583e-01 4.28941125e-01\n",
      " 3.35671913e-01 5.18546706e-01 7.87109323e-01 7.53747571e-02\n",
      " 5.06412992e-01 8.20254057e-01 3.34413314e-01 6.01601007e-01\n",
      " 5.54827881e-01 7.23418042e-02 6.20064086e-01 8.89571320e-01\n",
      " 6.99456251e-01 2.09763263e-01 6.68516347e-01 2.33964580e-01\n",
      " 7.86020478e-02 5.20535549e-01 7.13122810e-01 5.12981624e-01\n",
      " 1.81158968e-01 2.16228544e-01], predicted: [0.45474833 0.4559725  0.45419946 0.45450187 0.45585564 0.45421815\n",
      " 0.4550685  0.4547868  0.45452327 0.45536497 0.45434088 0.4548253\n",
      " 0.4547854  0.45553708 0.454996   0.4545542  0.45527324 0.45544562\n",
      " 0.45566353 0.45423526 0.4554006  0.4548295  0.45544824 0.4540807\n",
      " 0.4547802  0.45416182 0.45403573 0.4549328  0.45516318 0.45471162\n",
      " 0.45428964 0.4557949  0.45474154 0.45424166 0.45516622 0.4545583\n",
      " 0.45462608 0.45580208 0.4545316  0.45414123 0.45441657 0.45547408\n",
      " 0.45446137 0.45541432 0.4557872  0.45470673 0.45439678 0.45472535\n",
      " 0.45554376 0.45545813], n_params: 481 model_out: [0.45474833 0.4559725  0.45419946 0.45450187 0.45585564 0.45421815\n",
      " 0.4550685  0.4547868  0.45452327 0.45536497 0.45434088 0.4548253\n",
      " 0.4547854  0.45553708 0.454996   0.4545542  0.45527324 0.45544562\n",
      " 0.45566353 0.45423526 0.4554006  0.4548295  0.45544824 0.4540807\n",
      " 0.4547802  0.45416182 0.45403573 0.4549328  0.45516318 0.45471162\n",
      " 0.45428964 0.4557949  0.45474154 0.45424166 0.45516622 0.4545583\n",
      " 0.45462608 0.45580208 0.4545316  0.45414123 0.45441657 0.45547408\n",
      " 0.45446137 0.45541432 0.4557872  0.45470673 0.45439678 0.45472535\n",
      " 0.45554376 0.45545813]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 1000 SSE loss: 0.08775465965270995, l0 penalty: 7.94111083984375 total loss: 4.784788524627686\n",
      "accuracy: 0.0, actual: [0.30764535 0.06200521 0.98878508 0.7190903  0.75756964 0.26375811\n",
      " 0.81423212 0.56902059 0.45944772 0.13070624 0.31822656 0.3471398\n",
      " 0.04941394 0.96384525 0.96475062 0.1106671  0.33928814 0.56340746\n",
      " 0.48681865 0.56492329 0.86105383 0.81537125 0.41010138 0.52310581\n",
      " 0.18856046 0.45604781 0.76245352 0.25340822 0.24580262 0.99679214\n",
      " 0.22599421 0.962532   0.24860247 0.71298981 0.04488238 0.67372927\n",
      " 0.41643382 0.51367789 0.51061752 0.37990148 0.01794764 0.80771941\n",
      " 0.41246825 0.28481926 0.89542746 0.51598704 0.98335094 0.4560161\n",
      " 0.71131126 0.09003222], predicted: [0.44920164 0.44989774 0.44760108 0.4481951  0.4481208  0.4493266\n",
      " 0.44801128 0.44848505 0.44876957 0.4497045  0.44917148 0.44908923\n",
      " 0.44993317 0.4477223  0.44772053 0.44976082 0.44911155 0.4484959\n",
      " 0.44869164 0.448493   0.44792086 0.44800907 0.44891    0.44858837\n",
      " 0.44954064 0.44877923 0.44811133 0.44935608 0.4493777  0.44754204\n",
      " 0.44943407 0.44772482 0.44936976 0.4482069  0.4499459  0.44828272\n",
      " 0.448892   0.44861525 0.44862393 0.44899598 0.4500217  0.44802392\n",
      " 0.44890323 0.44926664 0.44785443 0.44860864 0.44764104 0.4487793\n",
      " 0.44821015 0.4498189 ], n_params: 481 model_out: [0.44920164 0.44989774 0.44760108 0.4481951  0.4481208  0.4493266\n",
      " 0.44801128 0.44848505 0.44876957 0.4497045  0.44917148 0.44908923\n",
      " 0.44993317 0.4477223  0.44772053 0.44976082 0.44911155 0.4484959\n",
      " 0.44869164 0.448493   0.44792086 0.44800907 0.44891    0.44858837\n",
      " 0.44954064 0.44877923 0.44811133 0.44935608 0.4493777  0.44754204\n",
      " 0.44943407 0.44772482 0.44936976 0.4482069  0.4499459  0.44828272\n",
      " 0.448892   0.44861525 0.44862393 0.44899598 0.4500217  0.44802392\n",
      " 0.44890323 0.44926664 0.44785443 0.44860864 0.44764104 0.4487793\n",
      " 0.44821015 0.4498189 ]\n",
      "\n",
      "epoch: 1100 SSE loss: 0.07862886428833007, l0 penalty: 7.935458374023438 total loss: 4.328216133117675\n",
      "accuracy: 0.0, actual: [0.11085918 0.16063585 0.32810561 0.76124781 0.20590416 0.32505251\n",
      " 0.76581979 0.74934728 0.84861718 0.39433213 0.17164583 0.21710032\n",
      " 0.10434461 0.55423068 0.00443751 0.02424124 0.71390035 0.77067714\n",
      " 0.49382951 0.95375253 0.93181453 0.18040305 0.8902187  0.61177194\n",
      " 0.39796743 0.8638849  0.50345533 0.28872712 0.05226651 0.67694834\n",
      " 0.05510032 0.47694611 0.3346869  0.16724479 0.9087095  0.17674362\n",
      " 0.2336313  0.09484772 0.33492619 0.11188002 0.98416995 0.47150125\n",
      " 0.26512476 0.5389784  0.25841541 0.3763732  0.23825235 0.86106258\n",
      " 0.14046733 0.47656548], predicted: [0.4432686  0.44310716 0.4425543  0.4412959  0.44295958 0.4425644\n",
      " 0.4412842  0.44132617 0.44107342 0.44233465 0.44307145 0.44292244\n",
      " 0.44328967 0.4418231  0.44361365 0.44354942 0.44141647 0.44127187\n",
      " 0.44200474 0.44080576 0.4408616  0.44304308 0.44096753 0.44167656\n",
      " 0.44232258 0.44103456 0.44197282 0.4426849  0.4434586  0.44151053\n",
      " 0.44344935 0.44206074 0.44253245 0.44308576 0.4409204  0.44305497\n",
      " 0.44286758 0.4433205  0.44253165 0.44326526 0.4405478  0.44207877\n",
      " 0.44276312 0.44186196 0.44278538 0.4423942  0.4428523  0.4410417\n",
      " 0.44317257 0.442062  ], n_params: 481 model_out: [0.4432686  0.44310716 0.4425543  0.4412959  0.44295958 0.4425644\n",
      " 0.4412842  0.44132617 0.44107342 0.44233465 0.44307145 0.44292244\n",
      " 0.44328967 0.4418231  0.44361365 0.44354942 0.44141647 0.44127187\n",
      " 0.44200474 0.44080576 0.4408616  0.44304308 0.44096753 0.44167656\n",
      " 0.44232258 0.44103456 0.44197282 0.4426849  0.4434586  0.44151053\n",
      " 0.44344935 0.44206074 0.44253245 0.44308576 0.4409204  0.44305497\n",
      " 0.44286758 0.4433205  0.44253165 0.44326526 0.4405478  0.44207877\n",
      " 0.44276312 0.44186196 0.44278538 0.4423942  0.4428523  0.4410417\n",
      " 0.44317257 0.442062  ]\n",
      "\n",
      "epoch: 1200 SSE loss: 0.05977933883666992, l0 penalty: 7.929939575195313 total loss: 3.3854639205932617\n",
      "accuracy: 0.0, actual: [0.92795478 0.90293699 0.42761683 0.5108057  0.58320012 0.95233031\n",
      " 0.2807887  0.79534532 0.97514    0.46315728 0.71245927 0.10283158\n",
      " 0.38714923 0.44845015 0.36039683 0.17294903 0.06502653 0.41469799\n",
      " 0.5538204  0.94282384 0.07855612 0.45039802 0.1004898  0.21781207\n",
      " 0.24807229 0.75919234 0.54424633 0.75070412 0.23970918 0.05135346\n",
      " 0.28893851 0.80654611 0.05652282 0.57953724 0.15759091 0.89388756\n",
      " 0.06860983 0.45601225 0.9451891  0.17636708 0.08282849 0.60873855\n",
      " 0.83260481 0.88980437 0.39324111 0.10517106 0.58080064 0.87034423\n",
      " 0.82323511 0.50066824], predicted: [0.43336794 0.43344882 0.43504995 0.43472615 0.4344827  0.43315893\n",
      " 0.4356216  0.43379667 0.4329352  0.4349116  0.4340647  0.43629757\n",
      " 0.43520746 0.43496883 0.43531162 0.4360324  0.4364406  0.43510023\n",
      " 0.4345777  0.43325222 0.43638945 0.43496126 0.43630648 0.43586278\n",
      " 0.4357484  0.43391356 0.43460867 0.433941   0.43578    0.43649226\n",
      " 0.43558982 0.43376046 0.43647274 0.4344945  0.4360905  0.4334781\n",
      " 0.43642706 0.43493938 0.43322906 0.4360195  0.43637323 0.43440008\n",
      " 0.43367624 0.4334913  0.43518373 0.43628877 0.43449044 0.4335542\n",
      " 0.43370646 0.43476564], n_params: 481 model_out: [0.43336794 0.43344882 0.43504995 0.43472615 0.4344827  0.43315893\n",
      " 0.4356216  0.43379667 0.4329352  0.4349116  0.4340647  0.43629757\n",
      " 0.43520746 0.43496883 0.43531162 0.4360324  0.4364406  0.43510023\n",
      " 0.4345777  0.43325222 0.43638945 0.43496126 0.43630648 0.43586278\n",
      " 0.4357484  0.43391356 0.43460867 0.433941   0.43578    0.43649226\n",
      " 0.43558982 0.43376046 0.43647274 0.4344945  0.4360905  0.4334781\n",
      " 0.43642706 0.43493938 0.43322906 0.4360195  0.43637323 0.43440008\n",
      " 0.43367624 0.4334913  0.43518373 0.43628877 0.43449044 0.4335542\n",
      " 0.43370646 0.43476564]\n",
      "\n",
      "epoch: 1300 SSE loss: 0.06309648036956787, l0 penalty: 7.9244873046875 total loss: 3.5510483837127684\n",
      "accuracy: 0.0, actual: [0.19743341 0.32748569 0.5565651  0.37699546 0.35406285 0.787998\n",
      " 0.48288545 0.72941558 0.75159744 0.95257541 0.10202835 0.92062934\n",
      " 0.23403776 0.45881805 0.5689398  0.74978382 0.86303411 0.93340374\n",
      " 0.04007018 0.7971857  0.55574092 0.94484971 0.55009522 0.4152211\n",
      " 0.65497206 0.86953129 0.74272704 0.40701026 0.34666637 0.80637197\n",
      " 0.39826655 0.0316977  0.77371336 0.41291077 0.77998257 0.14022418\n",
      " 0.10702905 0.62477661 0.12669245 0.62769946 0.03749244 0.89520706\n",
      " 0.04350655 0.58733528 0.31773529 0.50603765 0.50528856 0.64392022\n",
      " 0.87755907 0.81769585], predicted: [0.42829096 0.42771572 0.42668816 0.42749423 0.4275982  0.42573822\n",
      " 0.42700973 0.42597863 0.42588758 0.4247525  0.42871314 0.42511505\n",
      " 0.42812905 0.42711985 0.42663738 0.42589507 0.42543033 0.42497006\n",
      " 0.42898732 0.4257005  0.4266916  0.42484015 0.42671472 0.42731932\n",
      " 0.4262842  0.42540365 0.425924   0.4273569  0.4276309  0.4256628\n",
      " 0.4273969  0.42902443 0.42579684 0.42732984 0.42577106 0.42854413\n",
      " 0.42869097 0.42640814 0.42860398 0.4263961  0.42899874 0.42529833\n",
      " 0.42897213 0.42656183 0.42775887 0.4269038  0.42690724 0.42632952\n",
      " 0.42537075 0.42561635], n_params: 481 model_out: [0.42829096 0.42771572 0.42668816 0.42749423 0.4275982  0.42573822\n",
      " 0.42700973 0.42597863 0.42588758 0.4247525  0.42871314 0.42511505\n",
      " 0.42812905 0.42711985 0.42663738 0.42589507 0.42543033 0.42497006\n",
      " 0.42898732 0.4257005  0.4266916  0.42484015 0.42671472 0.42731932\n",
      " 0.4262842  0.42540365 0.425924   0.4273569  0.4276309  0.4256628\n",
      " 0.4273969  0.42902443 0.42579684 0.42732984 0.42577106 0.42854413\n",
      " 0.42869097 0.42640814 0.42860398 0.4263961  0.42899874 0.42529833\n",
      " 0.42897213 0.42656183 0.42775887 0.4269038  0.42690724 0.42632952\n",
      " 0.42537075 0.42561635]\n",
      "\n",
      "epoch: 1400 SSE loss: 0.07103389739990235, l0 penalty: 7.919139404296875 total loss: 3.9476518402099607\n",
      "accuracy: 0.0, actual: [0.6324735  0.07511275 0.72208355 0.46686221 0.74175255 0.85379163\n",
      " 0.49069912 0.13730356 0.0874282  0.46265935 0.98335529 0.9458497\n",
      " 0.88690902 0.19536225 0.22846274 0.16474929 0.32511731 0.96465814\n",
      " 0.26126882 0.07421599 0.66736014 0.44823688 0.94820275 0.99557233\n",
      " 0.76739491 0.40948648 0.87952573 0.53041588 0.97126908 0.54074854\n",
      " 0.5457392  0.23073446 0.00477072 0.5817624  0.06694742 0.8253965\n",
      " 0.94441458 0.62799042 0.71251061 0.01976274 0.13866541 0.20525631\n",
      " 0.45530487 0.62443994 0.53489423 0.56173756 0.82165743 0.04696861\n",
      " 0.98414718 0.76174376], predicted: [0.4178127  0.4207107  0.41735715 0.41867018 0.41725716 0.41668776\n",
      " 0.41854253 0.42038652 0.4206465  0.41869202 0.41532227 0.41580707\n",
      " 0.41651952 0.42008406 0.41991162 0.42024356 0.41940817 0.41556394\n",
      " 0.41974068 0.42071536 0.41763532 0.41876712 0.41577664 0.4151644\n",
      " 0.4171268  0.41896883 0.41655698 0.41833177 0.4154785  0.4182792\n",
      " 0.4182538  0.41989976 0.4210774  0.41807058 0.42075324 0.41683203\n",
      " 0.4158256  0.41783553 0.4174058  0.4209992  0.42037946 0.42003247\n",
      " 0.41873032 0.4178536  0.418309   0.41817245 0.4168511  0.4208574\n",
      " 0.41531208 0.41715556], n_params: 481 model_out: [0.4178127  0.4207107  0.41735715 0.41867018 0.41725716 0.41668776\n",
      " 0.41854253 0.42038652 0.4206465  0.41869202 0.41532227 0.41580707\n",
      " 0.41651952 0.42008406 0.41991162 0.42024356 0.41940817 0.41556394\n",
      " 0.41974068 0.42071536 0.41763532 0.41876712 0.41577664 0.4151644\n",
      " 0.4171268  0.41896883 0.41655698 0.41833177 0.4154785  0.4182792\n",
      " 0.4182538  0.41989976 0.4210774  0.41807058 0.42075324 0.41683203\n",
      " 0.4158256  0.41783553 0.4174058  0.4209992  0.42037946 0.42003247\n",
      " 0.41873032 0.4178536  0.418309   0.41817245 0.4168511  0.4208574\n",
      " 0.41531208 0.41715556]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 1500 SSE loss: 0.052677912712097166, l0 penalty: 7.913941650390625 total loss: 3.02959271812439\n",
      "accuracy: 0.0, actual: [0.24392333 0.65495435 0.35150695 0.62498055 0.03401694 0.24540688\n",
      " 0.22322093 0.0760436  0.83643934 0.88957214 0.18126889 0.78185092\n",
      " 0.59343407 0.1847256  0.37908656 0.9475536  0.01381148 0.47050336\n",
      " 0.78318807 0.62917569 0.36378382 0.02195515 0.8975815  0.50285664\n",
      " 0.29962934 0.04863477 0.9932151  0.81687624 0.16885527 0.88573366\n",
      " 0.06075629 0.8205812  0.25389633 0.99687541 0.04379909 0.15060614\n",
      " 0.78009182 0.02238677 0.13359511 0.23338146 0.22705116 0.39122358\n",
      " 0.77979902 0.18917251 0.32549157 0.44852835 0.3491879  0.64779936\n",
      " 0.98710881 0.02330982], predicted: [0.41055182 0.40802258 0.40989172 0.4082081  0.4118406  0.4105427\n",
      " 0.41067883 0.41158244 0.4068905  0.40642864 0.41093636 0.40723565\n",
      " 0.40840343 0.41091514 0.4097226  0.40556988 0.41196468 0.409162\n",
      " 0.40722728 0.4081821  0.40981644 0.41191468 0.40630996 0.4089637\n",
      " 0.41020995 0.41175076 0.40488216 0.4070142  0.41101253 0.4064855\n",
      " 0.41167632 0.40699077 0.41049057 0.40482628 0.4117805  0.41112462\n",
      " 0.4072468  0.41191202 0.411229   0.41061652 0.41065535 0.40964818\n",
      " 0.40724865 0.41088784 0.41005135 0.40929678 0.409906   0.40806684\n",
      " 0.40497532 0.41190636], n_params: 481 model_out: [0.41055182 0.40802258 0.40989172 0.4082081  0.4118406  0.4105427\n",
      " 0.41067883 0.41158244 0.4068905  0.40642864 0.41093636 0.40723565\n",
      " 0.40840343 0.41091514 0.4097226  0.40556988 0.41196468 0.409162\n",
      " 0.40722728 0.4081821  0.40981644 0.41191468 0.40630996 0.4089637\n",
      " 0.41020995 0.41175076 0.40488216 0.4070142  0.41101253 0.4064855\n",
      " 0.41167632 0.40699077 0.41049057 0.40482628 0.4117805  0.41112462\n",
      " 0.4072468  0.41191202 0.411229   0.41061652 0.41065535 0.40964818\n",
      " 0.40724865 0.41088784 0.41005135 0.40929678 0.409906   0.40806684\n",
      " 0.40497532 0.41190636]\n",
      "\n",
      "epoch: 1600 SSE loss: 0.05625310897827149, l0 penalty: 7.908800048828125 total loss: 3.2080954513549806\n",
      "accuracy: 0.0, actual: [1.10967488e-02 1.76979095e-03 1.55055120e-01 3.16761149e-01\n",
      " 6.51844892e-01 8.35250261e-01 4.85571203e-01 2.01753470e-01\n",
      " 2.25976088e-01 6.41811012e-01 9.24984367e-01 9.13262861e-01\n",
      " 3.71910602e-02 3.15295317e-01 3.07452482e-01 7.16460430e-01\n",
      " 4.42990668e-02 9.90909112e-01 2.20877031e-01 6.41567461e-01\n",
      " 3.39271949e-01 9.32724032e-01 3.47442712e-01 9.03533362e-01\n",
      " 3.22044877e-01 2.10897418e-01 4.23354756e-01 7.11419002e-02\n",
      " 3.30825461e-01 9.44439365e-01 3.72525990e-01 1.57532773e-01\n",
      " 8.27404128e-01 1.36221725e-01 5.87986482e-05 2.33790295e-01\n",
      " 2.51751980e-01 2.31221135e-01 7.88580413e-01 2.15475783e-01\n",
      " 4.57708642e-01 4.31598585e-01 4.86552109e-01 5.14822573e-01\n",
      " 1.69646528e-02 2.79798540e-01 8.55345511e-01 5.68367685e-01\n",
      " 1.87040158e-01 5.15802945e-01], predicted: [0.40236154 0.4024291  0.40131932 0.4001497  0.39768228 0.3962969\n",
      " 0.39892992 0.40098146 0.40080622 0.39775813 0.3949795  0.39517355\n",
      " 0.40217257 0.40016028 0.40021703 0.397194   0.4021211  0.39386043\n",
      " 0.4008431  0.39775997 0.39998698 0.39485142 0.3999279  0.39533463\n",
      " 0.4001115  0.4009153  0.3993793  0.40192673 0.40004805 0.3946526\n",
      " 0.39974663 0.4013014  0.39635614 0.4014556  0.4024415  0.40074968\n",
      " 0.40061978 0.4007683  0.39664924 0.40088218 0.39913115 0.39931977\n",
      " 0.3989228  0.39871833 0.40231904 0.40041697 0.3961328  0.39831334\n",
      " 0.40108794 0.39871094], n_params: 481 model_out: [0.40236154 0.4024291  0.40131932 0.4001497  0.39768228 0.3962969\n",
      " 0.39892992 0.40098146 0.40080622 0.39775813 0.3949795  0.39517355\n",
      " 0.40217257 0.40016028 0.40021703 0.397194   0.4021211  0.39386043\n",
      " 0.4008431  0.39775997 0.39998698 0.39485142 0.3999279  0.39533463\n",
      " 0.4001115  0.4009153  0.3993793  0.40192673 0.40004805 0.3946526\n",
      " 0.39974663 0.4013014  0.39635614 0.4014556  0.4024415  0.40074968\n",
      " 0.40061978 0.4007683  0.39664924 0.40088218 0.39913115 0.39931977\n",
      " 0.3989228  0.39871833 0.40231904 0.40041697 0.3961328  0.39831334\n",
      " 0.40108794 0.39871094]\n",
      "\n",
      "epoch: 1700 SSE loss: 0.0768812084197998, l0 penalty: 7.903666381835937 total loss: 4.239243740081787\n",
      "accuracy: 0.0, actual: [0.51581483 0.95028891 0.3888361  0.44491654 0.77613502 0.67884456\n",
      " 0.76739371 0.82794152 0.93792154 0.02433081 0.76375513 0.30719378\n",
      " 0.2232603  0.10107096 0.04237312 0.28610163 0.96747574 0.2916587\n",
      " 0.21365838 0.66738829 0.1636023  0.12742832 0.84142164 0.75478469\n",
      " 0.62375125 0.77797418 0.36505585 0.52144647 0.61365407 0.79053547\n",
      " 0.44751972 0.32958081 0.75380282 0.90534579 0.6728229  0.61213387\n",
      " 0.29109754 0.39218911 0.3360764  0.65429518 0.65596847 0.31003104\n",
      " 0.55415803 0.05783033 0.81628846 0.45986874 0.62778921 0.74188624\n",
      " 0.80057612 0.55827506], predicted: [0.3881743  0.38308    0.3892447  0.38877186 0.38581467 0.38669717\n",
      " 0.38589394 0.38534507 0.38331902 0.39232332 0.38592693 0.3899335\n",
      " 0.3906421  0.39167446 0.39217076 0.3901115  0.38274792 0.39006463\n",
      " 0.3907232  0.38680112 0.391146   0.39145166 0.38514155 0.38600826\n",
      " 0.38719723 0.385798   0.3894453  0.38812646 0.3872889  0.38568413\n",
      " 0.38874987 0.38974458 0.3860172  0.38394147 0.3867518  0.3873027\n",
      " 0.39006934 0.38921642 0.38968977 0.38691998 0.38690478 0.38990957\n",
      " 0.3878292  0.39204004 0.3854507  0.38864577 0.38716057 0.38612524\n",
      " 0.38559312 0.38779187], n_params: 481 model_out: [0.3881743  0.38308    0.3892447  0.38877186 0.38581467 0.38669717\n",
      " 0.38589394 0.38534507 0.38331902 0.39232332 0.38592693 0.3899335\n",
      " 0.3906421  0.39167446 0.39217076 0.3901115  0.38274792 0.39006463\n",
      " 0.3907232  0.38680112 0.391146   0.39145166 0.38514155 0.38600826\n",
      " 0.38719723 0.385798   0.3894453  0.38812646 0.3872889  0.38568413\n",
      " 0.38874987 0.38974458 0.3860172  0.38394147 0.3867518  0.3873027\n",
      " 0.39006934 0.38921642 0.38968977 0.38691998 0.38690478 0.38990957\n",
      " 0.3878292  0.39204004 0.3854507  0.38864577 0.38716057 0.38612524\n",
      " 0.38559312 0.38779187]\n",
      "\n",
      "epoch: 1800 SSE loss: 0.031080923080444335, l0 penalty: 7.898661499023437 total loss: 1.9489792289733887\n",
      "accuracy: 0.0, actual: [0.19112391 0.05854766 0.43681052 0.72029665 0.82441172 0.44750936\n",
      " 0.11723287 0.17410384 0.8527476  0.52609768 0.48841729 0.3802764\n",
      " 0.08025891 0.79924238 0.95515641 0.17080325 0.3424185  0.78724923\n",
      " 0.20694367 0.14706225 0.69230157 0.84115549 0.33477383 0.48561629\n",
      " 0.21895371 0.54200602 0.20179066 0.41754121 0.86385854 0.13858201\n",
      " 0.84242243 0.03208219 0.44088815 0.2004808  0.6827069  0.82856309\n",
      " 0.68655476 0.14562663 0.76667869 0.06222087 0.34157644 0.35535889\n",
      " 0.53754194 0.91972692 0.56710232 0.31742526 0.99780975 0.07567632\n",
      " 0.10207756 0.61363548], predicted: [0.38006946 0.38138607 0.37763423 0.3746554  0.37343234 0.3775283\n",
      " 0.38080308 0.38023838 0.37283155 0.3767507  0.37712348 0.37819406\n",
      " 0.38117036 0.37380442 0.37061703 0.38027114 0.3785691  0.37393367\n",
      " 0.37991247 0.38050687 0.37495735 0.37307733 0.37864485 0.37715122\n",
      " 0.37979332 0.37658003 0.3799636  0.377825   0.3725961  0.3805911\n",
      " 0.37305045 0.3816491  0.37759387 0.37997663 0.37506086 0.37334433\n",
      " 0.37501934 0.38052112 0.37415534 0.3813496  0.37857747 0.3784409\n",
      " 0.37662825 0.37139058 0.37630886 0.3788168  0.36968663 0.38121587\n",
      " 0.38095364 0.37580636], n_params: 481 model_out: [0.38006946 0.38138607 0.37763423 0.3746554  0.37343234 0.3775283\n",
      " 0.38080308 0.38023838 0.37283155 0.3767507  0.37712348 0.37819406\n",
      " 0.38117036 0.37380442 0.37061703 0.38027114 0.3785691  0.37393367\n",
      " 0.37991247 0.38050687 0.37495735 0.37307733 0.37864485 0.37715122\n",
      " 0.37979332 0.37658003 0.3799636  0.377825   0.3725961  0.3805911\n",
      " 0.37305045 0.3816491  0.37759387 0.37997663 0.37506086 0.37334433\n",
      " 0.37501934 0.38052112 0.37415534 0.3813496  0.37857747 0.3784409\n",
      " 0.37662825 0.37139058 0.37630886 0.3788168  0.36968663 0.38121587\n",
      " 0.38095364 0.37580636]\n",
      "\n",
      "epoch: 1900 SSE loss: 0.045723276138305666, l0 penalty: 7.893565063476562 total loss: 2.680842060089111\n",
      "accuracy: 0.0, actual: [0.96313608 0.61881857 0.11579477 0.63654109 0.35393578 0.89169112\n",
      " 0.06128091 0.32980809 0.79257895 0.75430396 0.50440497 0.01351044\n",
      " 0.29597513 0.71974    0.5783697  0.07746732 0.98142979 0.64174917\n",
      " 0.00112201 0.8953285  0.71434441 0.01214464 0.29614204 0.79465339\n",
      " 0.6087835  0.28903215 0.96825692 0.93571533 0.04830588 0.28682568\n",
      " 0.53600413 0.09549094 0.99397257 0.48282981 0.02361421 0.40459587\n",
      " 0.11163784 0.52488166 0.42333147 0.63251852 0.31731665 0.86291236\n",
      " 0.00996363 0.80233664 0.00845253 0.30627878 0.19068172 0.4310169\n",
      " 0.16587362 0.98718401], predicted: [0.35793182 0.3641379  0.36998788 0.36391515 0.3672607  0.35966778\n",
      " 0.37061337 0.3675366  0.36195618 0.36243623 0.36554188 0.3711618\n",
      " 0.3679237  0.36287004 0.3646466  0.37042758 0.3574879  0.36384967\n",
      " 0.3713041  0.35957932 0.36293775 0.37117746 0.3679218  0.36193013\n",
      " 0.36426407 0.36800313 0.35780752 0.35859764 0.37076226 0.3680284\n",
      " 0.36517975 0.37022078 0.35718364 0.36578816 0.37104574 0.36668164\n",
      " 0.37003553 0.36530823 0.36646757 0.36396566 0.3676795  0.36036813\n",
      " 0.3712025  0.36179882 0.37121987 0.36780578 0.36912936 0.36637977\n",
      " 0.3694137  0.3573483 ], n_params: 481 model_out: [0.35793182 0.3641379  0.36998788 0.36391515 0.3672607  0.35966778\n",
      " 0.37061337 0.3675366  0.36195618 0.36243623 0.36554188 0.3711618\n",
      " 0.3679237  0.36287004 0.3646466  0.37042758 0.3574879  0.36384967\n",
      " 0.3713041  0.35957932 0.36293775 0.37117746 0.3679218  0.36193013\n",
      " 0.36426407 0.36800313 0.35780752 0.35859764 0.37076226 0.3680284\n",
      " 0.36517975 0.37022078 0.35718364 0.36578816 0.37104574 0.36668164\n",
      " 0.37003553 0.36530823 0.36646757 0.36396566 0.3676795  0.36036813\n",
      " 0.3712025  0.36179882 0.37121987 0.36780578 0.36912936 0.36637977\n",
      " 0.3694137  0.3573483 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 2000 SSE loss: 0.039977831840515135, l0 penalty: 7.888450317382812 total loss: 2.3933141078948976\n",
      "accuracy: 0.0, actual: [0.53525707 0.90404425 0.50239657 0.10087001 0.52758198 0.71122893\n",
      " 0.31295428 0.05032535 0.12328206 0.77969075 0.94802187 0.71818603\n",
      " 0.75389358 0.10964897 0.63814993 0.28945067 0.361702   0.00315978\n",
      " 0.04352426 0.79419409 0.77746827 0.56411938 0.38736774 0.34514564\n",
      " 0.41004102 0.06705749 0.97356847 0.06405922 0.10844153 0.47859636\n",
      " 0.87148378 0.98030973 0.67780738 0.87716066 0.26757641 0.61586974\n",
      " 0.44980164 0.61761576 0.80281463 0.03813337 0.29641567 0.33406014\n",
      " 0.50907489 0.74504766 0.59307464 0.34360118 0.30266013 0.27967976\n",
      " 0.92107048 0.87532113], predicted: [0.3529567  0.34606403 0.35338718 0.35866645 0.35305724 0.3504048\n",
      " 0.35587364 0.35933346 0.35837087 0.3493985  0.34487417 0.3503037\n",
      " 0.34978524 0.35855064 0.35146713 0.35618263 0.35523304 0.35995638\n",
      " 0.35942325 0.34901768 0.34944317 0.35254478 0.354896   0.35545057\n",
      " 0.3545984  0.35911262 0.3441839  0.35915217 0.35856658 0.35369915\n",
      " 0.34694624 0.3440018  0.35089043 0.34679234 0.35647035 0.35179132\n",
      " 0.35407668 0.3517659  0.34879148 0.35949448 0.35609105 0.35559618\n",
      " 0.3532997  0.34991366 0.3521231  0.35547084 0.35600898 0.35631117\n",
      " 0.34560314 0.3468422 ], n_params: 481 model_out: [0.3529567  0.34606403 0.35338718 0.35866645 0.35305724 0.3504048\n",
      " 0.35587364 0.35933346 0.35837087 0.3493985  0.34487417 0.3503037\n",
      " 0.34978524 0.35855064 0.35146713 0.35618263 0.35523304 0.35995638\n",
      " 0.35942325 0.34901768 0.34944317 0.35254478 0.354896   0.35545057\n",
      " 0.3545984  0.35911262 0.3441839  0.35915217 0.35856658 0.35369915\n",
      " 0.34694624 0.3440018  0.35089043 0.34679234 0.35647035 0.35179132\n",
      " 0.35407668 0.3517659  0.34879148 0.35949448 0.35609105 0.35559618\n",
      " 0.3532997  0.34991366 0.3521231  0.35547084 0.35600898 0.35631117\n",
      " 0.34560314 0.3468422 ]\n",
      "\n",
      "epoch: 2100 SSE loss: 0.01993661403656006, l0 penalty: 7.883361206054688 total loss: 1.3909987621307374\n",
      "accuracy: 0.0, actual: [0.19116441 0.88396212 0.02326298 0.20884131 0.51179856 0.56879329\n",
      " 0.57361472 0.49483054 0.76162295 0.30192289 0.27155945 0.99691651\n",
      " 0.67875275 0.99591636 0.0675118  0.50865378 0.53797197 0.30963577\n",
      " 0.41166863 0.97419633 0.55560165 0.22116779 0.8298579  0.87640543\n",
      " 0.6172649  0.58731953 0.75068405 0.49894222 0.32379603 0.58381338\n",
      " 0.47685693 0.00621622 0.75069978 0.9626833  0.40337594 0.42000162\n",
      " 0.73998249 0.03698031 0.38871876 0.86455517 0.16777009 0.65678607\n",
      " 0.82159339 0.70039345 0.52998833 0.08064094 0.04805675 0.7468486\n",
      " 0.39704362 0.51506341], predicted: [0.34533304 0.33286446 0.34784684 0.34506887 0.3405566  0.33967713\n",
      " 0.33959672 0.3408086  0.33646953 0.3436795  0.34413242 0.3295067\n",
      " 0.33784622 0.32953638 0.34718353 0.3406033  0.3401681  0.34356448\n",
      " 0.34204477 0.3301807  0.33989707 0.34488472 0.33447886 0.3330897\n",
      " 0.33886942 0.33936828 0.33665112 0.3407475  0.3433534  0.33942673\n",
      " 0.34107557 0.3481025  0.33665085 0.33052254 0.34216818 0.34192085\n",
      " 0.3368288  0.3476411  0.34238634 0.3334431  0.34568277 0.3382116\n",
      " 0.33472583 0.33748645 0.34028655 0.34698677 0.34747508 0.3367148\n",
      " 0.34226242 0.3405081 ], n_params: 481 model_out: [0.34533304 0.33286446 0.34784684 0.34506887 0.3405566  0.33967713\n",
      " 0.33959672 0.3408086  0.33646953 0.3436795  0.34413242 0.3295067\n",
      " 0.33784622 0.32953638 0.34718353 0.3406033  0.3401681  0.34356448\n",
      " 0.34204477 0.3301807  0.33989707 0.34488472 0.33447886 0.3330897\n",
      " 0.33886942 0.33936828 0.33665112 0.3407475  0.3433534  0.33942673\n",
      " 0.34107557 0.3481025  0.33665085 0.33052254 0.34216818 0.34192085\n",
      " 0.3368288  0.3476411  0.34238634 0.3334431  0.34568277 0.3382116\n",
      " 0.33472583 0.33748645 0.34028655 0.34698677 0.34747508 0.3367148\n",
      " 0.34226242 0.3405081 ]\n",
      "\n",
      "epoch: 2200 SSE loss: 0.03819900989532471, l0 penalty: 7.87815185546875 total loss: 2.303858087539673\n",
      "accuracy: 0.0, actual: [0.51209396 0.71948803 0.27923902 0.78823856 0.38226036 0.62064816\n",
      " 0.23504853 0.29133122 0.83758465 0.5555624  0.78575222 0.50304687\n",
      " 0.93417111 0.63196177 0.55118677 0.18374238 0.33838898 0.34121671\n",
      " 0.46346542 0.04258595 0.62584    0.73013775 0.66883239 0.81420231\n",
      " 0.56620278 0.35015504 0.10399446 0.50939619 0.88731511 0.0324091\n",
      " 0.51557402 0.49957906 0.62989025 0.37444687 0.81158468 0.06981561\n",
      " 0.37537804 0.49967665 0.59171163 0.39043263 0.66361867 0.53203963\n",
      " 0.57591425 0.44875814 0.97160315 0.51101676 0.40089466 0.13397944\n",
      " 0.10916704 0.43877132], predicted: [0.3280117  0.32422125 0.331902   0.32236415 0.33017796 0.32607415\n",
      " 0.3326429  0.33169943 0.32074684 0.32728806 0.32244575 0.3281624\n",
      " 0.31759366 0.32586178 0.32736087 0.33350414 0.33091158 0.33086425\n",
      " 0.3288222  0.3358794  0.3259767  0.3240219  0.32517016 0.32151264\n",
      " 0.32709718 0.33071473 0.33484507 0.32805666 0.31912124 0.336051\n",
      " 0.32795373 0.32822022 0.32590067 0.3303086  0.32159844 0.33542055\n",
      " 0.330293   0.32821855 0.32661763 0.3300414  0.32526794 0.32767954\n",
      " 0.32691455 0.32906753 0.31637612 0.32802963 0.32986662 0.33434057\n",
      " 0.33475798 0.32923418], n_params: 481 model_out: [0.3280117  0.32422125 0.331902   0.32236415 0.33017796 0.32607415\n",
      " 0.3326429  0.33169943 0.32074684 0.32728806 0.32244575 0.3281624\n",
      " 0.31759366 0.32586178 0.32736087 0.33350414 0.33091158 0.33086425\n",
      " 0.3288222  0.3358794  0.3259767  0.3240219  0.32517016 0.32151264\n",
      " 0.32709718 0.33071473 0.33484507 0.32805666 0.31912124 0.336051\n",
      " 0.32795373 0.32822022 0.32590067 0.3303086  0.32159844 0.33542055\n",
      " 0.330293   0.32821855 0.32661763 0.3300414  0.32526794 0.32767954\n",
      " 0.32691455 0.32906753 0.31637612 0.32802963 0.32986662 0.33434057\n",
      " 0.33475798 0.32923418]\n",
      "\n",
      "epoch: 2300 SSE loss: 0.020476317405700682, l0 penalty: 7.872911376953125 total loss: 1.4174614391326905\n",
      "accuracy: 0.0, actual: [0.01787916 0.45859407 0.23321961 0.75685128 0.02824753 0.15179412\n",
      " 0.76922643 0.46571975 0.34395039 0.12231006 0.9288571  0.55512641\n",
      " 0.92644836 0.6239372  0.39030061 0.42427864 0.5537456  0.04429094\n",
      " 0.40286324 0.91501629 0.87059731 0.39501556 0.2302167  0.43527746\n",
      " 0.95954422 0.29269382 0.32503584 0.67175748 0.05851872 0.50097987\n",
      " 0.93194832 0.08880909 0.19903272 0.57951172 0.10604744 0.54428014\n",
      " 0.00349382 0.34248391 0.62808072 0.46970057 0.29998452 0.38219436\n",
      " 0.63235182 0.34160582 0.29389866 0.27730244 0.11205505 0.38134216\n",
      " 0.37797161 0.1062966 ], predicted: [0.32458654 0.31644166 0.32059315 0.31017485 0.32439363 0.3221001\n",
      " 0.30973598 0.31631085 0.31854984 0.32264665 0.304106   0.31467235\n",
      " 0.30419052 0.31328905 0.3176966  0.3170719  0.31469762 0.32409534\n",
      " 0.31746554 0.30459183 0.30615407 0.31760988 0.32064864 0.31686983\n",
      " 0.30303028 0.3194948  0.31889838 0.31229764 0.3238309  0.3156641\n",
      " 0.30399755 0.3232683  0.32122537 0.3142116  0.32294837 0.3148709\n",
      " 0.3248542  0.3185769  0.3132031  0.3162378  0.3193603  0.31784573\n",
      " 0.3131145  0.31859306 0.31947258 0.31977883 0.3228369  0.3178614\n",
      " 0.31792346 0.32294375], n_params: 481 model_out: [0.32458654 0.31644166 0.32059315 0.31017485 0.32439363 0.3221001\n",
      " 0.30973598 0.31631085 0.31854984 0.32264665 0.304106   0.31467235\n",
      " 0.30419052 0.31328905 0.3176966  0.3170719  0.31469762 0.32409534\n",
      " 0.31746554 0.30459183 0.30615407 0.31760988 0.32064864 0.31686983\n",
      " 0.30303028 0.3194948  0.31889838 0.31229764 0.3238309  0.3156641\n",
      " 0.30399755 0.3232683  0.32122537 0.3142116  0.32294837 0.3148709\n",
      " 0.3248542  0.3185769  0.3132031  0.3162378  0.3193603  0.31784573\n",
      " 0.3131145  0.31859306 0.31947258 0.31977883 0.3228369  0.3178614\n",
      " 0.31792346 0.32294375]\n",
      "\n",
      "epoch: 2400 SSE loss: 0.01576364278793335, l0 penalty: 7.867536010742188 total loss: 1.181558939933777\n",
      "accuracy: 0.0, actual: [0.62369858 0.13642735 0.89358378 0.31807511 0.57900906 0.49398569\n",
      " 0.62027392 0.64934675 0.25939655 0.88880075 0.07908498 0.38016763\n",
      " 0.24383419 0.20658332 0.70709294 0.08420088 0.91928692 0.17185967\n",
      " 0.1454558  0.66842081 0.15486786 0.76672022 0.01876021 0.98518226\n",
      " 0.43769148 0.76539371 0.28304419 0.31587564 0.23886022 0.52239538\n",
      " 0.98070355 0.33116667 0.56040343 0.81267399 0.46468859 0.21151295\n",
      " 0.36841162 0.88057002 0.40377913 0.71418454 0.4197624  0.24490822\n",
      " 0.2886603  0.54769727 0.61598963 0.73885102 0.84458987 0.68068938\n",
      " 0.96767001 0.60127676], predicted: [0.3005384  0.31047162 0.29167536 0.30678508 0.30153242 0.30323836\n",
      " 0.30061644 0.29995427 0.3079733  0.29185596 0.31164044 0.30553055\n",
      " 0.30828887 0.30904493 0.29860517 0.31153604 0.29070604 0.30975062\n",
      " 0.31028783 0.2995203  0.3100963  0.29648745 0.31287262 0.2882296\n",
      " 0.30437085 0.29653803 0.30749413 0.30682957 0.30838975 0.30266774\n",
      " 0.28839755 0.30652034 0.30190527 0.2947391  0.30382743 0.30894482\n",
      " 0.30576783 0.29216686 0.30505422 0.2984338  0.30473202 0.3082671\n",
      " 0.3073804  0.30216005 0.30071408 0.29755068 0.2935283  0.29924136\n",
      " 0.28888655 0.30104956], n_params: 481 model_out: [0.3005384  0.31047162 0.29167536 0.30678508 0.30153242 0.30323836\n",
      " 0.30061644 0.29995427 0.3079733  0.29185596 0.31164044 0.30553055\n",
      " 0.30828887 0.30904493 0.29860517 0.31153604 0.29070604 0.30975062\n",
      " 0.31028783 0.2995203  0.3100963  0.29648745 0.31287262 0.2882296\n",
      " 0.30437085 0.29653803 0.30749413 0.30682957 0.30838975 0.30266774\n",
      " 0.28839755 0.30652034 0.30190527 0.2947391  0.30382743 0.30894482\n",
      " 0.30576783 0.29216686 0.30505422 0.2984338  0.30473202 0.3082671\n",
      " 0.3073804  0.30216005 0.30071408 0.29755068 0.2935283  0.29924136\n",
      " 0.28888655 0.30104956]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 2500 SSE loss: 0.018952257633209228, l0 penalty: 7.861978759765625 total loss: 1.3407118196487426\n",
      "accuracy: 0.0, actual: [0.70234877 0.24126003 0.3909774  0.08272685 0.0125667  0.09097745\n",
      " 0.88338182 0.73286425 0.88013022 0.92964604 0.4807014  0.40341409\n",
      " 0.3506564  0.54586824 0.79552717 0.07982766 0.7188167  0.62327477\n",
      " 0.28242463 0.76059583 0.50328887 0.33464501 0.76103674 0.06868315\n",
      " 0.71545598 0.56427928 0.10325397 0.29758537 0.73224651 0.33388648\n",
      " 0.910522   0.26858995 0.43681056 0.24196784 0.04470311 0.49783801\n",
      " 0.40223873 0.9800457  0.47167284 0.66310306 0.4971505  0.80088507\n",
      " 0.41198731 0.12023148 0.7414398  0.5854993  0.44173437 0.23205948\n",
      " 0.10164505 0.48847288], predicted: [0.28598195 0.2964123  0.2931229  0.2999185  0.30147773 0.29973546\n",
      " 0.27873567 0.28480873 0.27886602 0.27688506 0.2911619  0.2928506\n",
      " 0.29400668 0.28974247 0.28227076 0.29998285 0.28537956 0.2880049\n",
      " 0.29550576 0.28368384 0.29066944 0.29435804 0.283666   0.30023023\n",
      " 0.28551623 0.2893422  0.29946318 0.29517227 0.28483382 0.2943747\n",
      " 0.27764913 0.29581022 0.29212022 0.29639667 0.30076298 0.29078823\n",
      " 0.29287636 0.27487764 0.2913589  0.28701198 0.29080325 0.2820544\n",
      " 0.292663   0.29908687 0.2844606  0.28888127 0.2920126  0.2966151\n",
      " 0.2994989  0.2909924 ], n_params: 481 model_out: [0.28598195 0.2964123  0.2931229  0.2999185  0.30147773 0.29973546\n",
      " 0.27873567 0.28480873 0.27886602 0.27688506 0.2911619  0.2928506\n",
      " 0.29400668 0.28974247 0.28227076 0.29998285 0.28537956 0.2880049\n",
      " 0.29550576 0.28368384 0.29066944 0.29435804 0.283666   0.30023023\n",
      " 0.28551623 0.2893422  0.29946318 0.29517227 0.28483382 0.2943747\n",
      " 0.27764913 0.29581022 0.29212022 0.29639667 0.30076298 0.29078823\n",
      " 0.29287636 0.27487764 0.2913589  0.28701198 0.29080325 0.2820544\n",
      " 0.292663   0.29908687 0.2844606  0.28888127 0.2920126  0.2966151\n",
      " 0.2994989  0.2909924 ]\n",
      "\n",
      "epoch: 2600 SSE loss: 0.011196268796920776, l0 penalty: 7.856295776367188 total loss: 0.9526282286643982\n",
      "accuracy: 0.0, actual: [0.69039982 0.53469    0.54891086 0.14741996 0.49835493 0.74789465\n",
      " 0.88905158 0.66779222 0.30704327 0.16873311 0.90018187 0.37078401\n",
      " 0.86328824 0.16120001 0.74392825 0.73136724 0.88378241 0.40817778\n",
      " 0.42255354 0.82676462 0.55791785 0.97911005 0.94111446 0.72408849\n",
      " 0.22635331 0.22294768 0.37309636 0.19286883 0.42527647 0.50042136\n",
      " 0.78324777 0.94384404 0.52292449 0.04578099 0.75336321 0.32138243\n",
      " 0.62055679 0.89630652 0.67965325 0.19714015 0.28720904 0.41647017\n",
      " 0.4251438  0.15548119 0.55103135 0.81855722 0.75443202 0.30515116\n",
      " 0.4500164  0.59782626], predicted: [0.27378443 0.27774996 0.2774154  0.28695548 0.27860588 0.2713296\n",
      " 0.26530382 0.27442443 0.28313914 0.28644413 0.26483238 0.2816238\n",
      " 0.26639724 0.28662482 0.27150017 0.27204072 0.26552722 0.28073713\n",
      " 0.28039673 0.2679522  0.27720365 0.26150435 0.26310307 0.27235427\n",
      " 0.28506446 0.2851459  0.28156894 0.28586575 0.28033227 0.27855715\n",
      " 0.26981238 0.26298803 0.2780269  0.28940147 0.2710946  0.28279784\n",
      " 0.27573368 0.2649965  0.27408853 0.28576344 0.28361166 0.28054073\n",
      " 0.28033543 0.28676203 0.27736557 0.26830244 0.27104867 0.2831842\n",
      " 0.2797471  0.27626655], n_params: 481 model_out: [0.27378443 0.27774996 0.2774154  0.28695548 0.27860588 0.2713296\n",
      " 0.26530382 0.27442443 0.28313914 0.28644413 0.26483238 0.2816238\n",
      " 0.26639724 0.28662482 0.27150017 0.27204072 0.26552722 0.28073713\n",
      " 0.28039673 0.2679522  0.27720365 0.26150435 0.26310307 0.27235427\n",
      " 0.28506446 0.2851459  0.28156894 0.28586575 0.28033227 0.27855715\n",
      " 0.26981238 0.26298803 0.2780269  0.28940147 0.2710946  0.28279784\n",
      " 0.27573368 0.2649965  0.27408853 0.28576344 0.28361166 0.28054073\n",
      " 0.28033543 0.28676203 0.27736557 0.26830244 0.27104867 0.2831842\n",
      " 0.2797471  0.27626655]\n",
      "\n",
      "epoch: 2700 SSE loss: 0.04186066627502441, l0 penalty: 7.8503265380859375 total loss: 2.4855496406555178\n",
      "accuracy: 0.0, actual: [0.35861256 0.2583149  0.3322382  0.56146181 0.80669874 0.66344814\n",
      " 0.62811623 0.71799402 0.62701845 0.69836772 0.81532173 0.2747042\n",
      " 0.87625913 0.2324739  0.06301098 0.86197497 0.97628903 0.879711\n",
      " 0.92971479 0.75016963 0.22458823 0.09721364 0.11742403 0.70621951\n",
      " 0.58367177 0.90227076 0.02793048 0.63156287 0.97081172 0.94596444\n",
      " 0.12382226 0.00706274 0.95196343 0.8213216  0.43756156 0.07773359\n",
      " 0.06545368 0.79613532 0.83572202 0.92388837 0.91523863 0.77362981\n",
      " 0.65033878 0.93806813 0.67927658 0.60531959 0.0827035  0.09469698\n",
      " 0.72693662 0.70764689], predicted: [0.2709708  0.27351606 0.27163866 0.26586884 0.25697088 0.26312333\n",
      " 0.26415783 0.26095003 0.26418716 0.2618358  0.25658616 0.27309912\n",
      " 0.25387838 0.27417424 0.27851477 0.25451145 0.24947456 0.2537256\n",
      " 0.2515186  0.25950208 0.27437526 0.27763534 0.27711648 0.26148123\n",
      " 0.26531398 0.25272828 0.27941856 0.26406586 0.2497144  0.25080422\n",
      " 0.27695236 0.27995706 0.2505408  0.25631875 0.26897785 0.27813601\n",
      " 0.27845195 0.25744262 0.25567758 0.25177512 0.25215623 0.2584496\n",
      " 0.26351863 0.2511512  0.2626466  0.26476675 0.27800822 0.27769998\n",
      " 0.26054704 0.26141676], n_params: 481 model_out: [0.2709708  0.27351606 0.27163866 0.26586884 0.25697088 0.26312333\n",
      " 0.26415783 0.26095003 0.26418716 0.2618358  0.25658616 0.27309912\n",
      " 0.25387838 0.27417424 0.27851477 0.25451145 0.24947456 0.2537256\n",
      " 0.2515186  0.25950208 0.27437526 0.27763534 0.27711648 0.26148123\n",
      " 0.26531398 0.25272828 0.27941856 0.26406586 0.2497144  0.25080422\n",
      " 0.27695236 0.27995706 0.2505408  0.25631875 0.26897785 0.27813601\n",
      " 0.27845195 0.25744262 0.25567758 0.25177512 0.25215623 0.2584496\n",
      " 0.26351863 0.2511512  0.2626466  0.26476675 0.27800822 0.27769998\n",
      " 0.26054704 0.26141676]\n",
      "\n",
      "epoch: 2800 SSE loss: 0.03622425317764282, l0 penalty: 7.84431640625 total loss: 2.203428479194641\n",
      "accuracy: 0.0, actual: [0.07759745 0.79611091 0.48534816 0.83481838 0.52345062 0.28310392\n",
      " 0.40546292 0.73126577 0.39027694 0.49801373 0.1250156  0.42466821\n",
      " 0.01554203 0.67112975 0.75749527 0.05243531 0.89226175 0.33396261\n",
      " 0.93856676 0.21039594 0.77136798 0.50120603 0.73284664 0.4300878\n",
      " 0.16144702 0.74473471 0.13153002 0.13592385 0.81365558 0.71785939\n",
      " 0.68922543 0.90478377 0.38838261 0.99964573 0.56721776 0.39550272\n",
      " 0.53603253 0.72495368 0.93339649 0.44635094 0.08273864 0.84819508\n",
      " 0.39764742 0.4494063  0.96472517 0.54778645 0.72923399 0.23526354\n",
      " 0.23711626 0.7364778 ], predicted: [0.26760727 0.24559847 0.25661358 0.2438022  0.25560156 0.2620293\n",
      " 0.25874397 0.2486276  0.25915024 0.2562769  0.26631355 0.25823075\n",
      " 0.26930636 0.251459   0.24739932 0.2682954  0.24115299 0.26066047\n",
      " 0.23903178 0.2639942  0.24675134 0.2561921  0.24855347 0.25808603\n",
      " 0.26532227 0.24799636 0.26613614 0.2660165  0.24478324 0.24925698\n",
      " 0.25060475 0.2405781  0.25920096 0.2362534  0.25444221 0.25901037\n",
      " 0.2552679  0.24892384 0.239268   0.25765213 0.2674668  0.24318355\n",
      " 0.258953   0.25757065 0.23783916 0.2549565  0.24872291 0.26332107\n",
      " 0.26327097 0.24838322], n_params: 481 model_out: [0.26760727 0.24559847 0.25661358 0.2438022  0.25560156 0.2620293\n",
      " 0.25874397 0.2486276  0.25915024 0.2562769  0.26631355 0.25823075\n",
      " 0.26930636 0.251459   0.24739932 0.2682954  0.24115299 0.26066047\n",
      " 0.23903178 0.2639942  0.24675134 0.2561921  0.24855347 0.25808603\n",
      " 0.26532227 0.24799636 0.26613614 0.2660165  0.24478324 0.24925698\n",
      " 0.25060475 0.2405781  0.25920096 0.2362534  0.25444221 0.25901037\n",
      " 0.2552679  0.24892384 0.239268   0.25765213 0.2674668  0.24318355\n",
      " 0.258953   0.25757065 0.23783916 0.2549565  0.24872291 0.26332107\n",
      " 0.26327097 0.24838322]\n",
      "\n",
      "epoch: 2900 SSE loss: 0.012472656965255737, l0 penalty: 7.838191528320312 total loss: 1.0155424246788025\n",
      "accuracy: 0.0, actual: [0.06952844 0.05756135 0.86240301 0.73616142 0.45155575 0.29682572\n",
      " 0.30917492 0.76168216 0.73809186 0.97638302 0.08716012 0.01654703\n",
      " 0.51893011 0.13315636 0.22251046 0.90360057 0.85863492 0.48933945\n",
      " 0.59902315 0.50224558 0.9492769  0.99386887 0.85955761 0.73876738\n",
      " 0.29806245 0.13293679 0.83719526 0.44607813 0.67262007 0.11926369\n",
      " 0.31621712 0.14769744 0.73050131 0.19902782 0.11905446 0.82284089\n",
      " 0.80316923 0.67589402 0.64516784 0.61698323 0.11633633 0.12609086\n",
      " 0.44134093 0.65456198 0.41608271 0.45347027 0.76762134 0.78317689\n",
      " 0.03993001 0.02010808], predicted: [0.25789294 0.25823757 0.23133448 0.23740385 0.2470502  0.2514046\n",
      " 0.25105518 0.23616806 0.23731023 0.22594844 0.2573858  0.25942096\n",
      " 0.24517007 0.25606567 0.253514   0.22937743 0.231514   0.24599461\n",
      " 0.24286434 0.24563476 0.22722124 0.22513008 0.23147008 0.2372775\n",
      " 0.2513696  0.25607198 0.23253766 0.24720345 0.24049996 0.25646397\n",
      " 0.2508561  0.2556493  0.2376785  0.25418296 0.25646996 0.23322476\n",
      " 0.23416871 0.24033973 0.24149887 0.24233225 0.2565479  0.2562682\n",
      " 0.24733607 0.24122153 0.248044   0.24699663 0.23588113 0.23513071\n",
      " 0.25874585 0.25931805], n_params: 481 model_out: [0.25789294 0.25823757 0.23133448 0.23740385 0.2470502  0.2514046\n",
      " 0.25105518 0.23616806 0.23731023 0.22594844 0.2573858  0.25942096\n",
      " 0.24517007 0.25606567 0.253514   0.22937743 0.231514   0.24599461\n",
      " 0.24286434 0.24563476 0.22722124 0.22513008 0.23147008 0.2372775\n",
      " 0.2513696  0.25607198 0.23253766 0.24720345 0.24049996 0.25646397\n",
      " 0.2508561  0.2556493  0.2376785  0.25418296 0.25646996 0.23322476\n",
      " 0.23416871 0.24033973 0.24149887 0.24233225 0.2565479  0.2562682\n",
      " 0.24733607 0.24122153 0.248044   0.24699663 0.23588113 0.23513071\n",
      " 0.25874585 0.25931805]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 3000 SSE loss: 0.00557354986667633, l0 penalty: 7.83185302734375 total loss: 0.670270144701004\n",
      "accuracy: 0.0, actual: [0.6226517  0.82421794 0.28428344 0.87839639 0.64116389 0.88815645\n",
      " 0.76152797 0.37503038 0.92185572 0.29182224 0.41247687 0.4641012\n",
      " 0.25166247 0.81322924 0.12431812 0.43852124 0.16661531 0.25279386\n",
      " 0.25963365 0.6609033  0.49987259 0.6382574  0.46343688 0.22698828\n",
      " 0.97664225 0.97426234 0.20306161 0.32619469 0.69963976 0.23739341\n",
      " 0.39503501 0.74172975 0.94369034 0.47140019 0.0632019  0.61826634\n",
      " 0.08297844 0.93694758 0.28686746 0.31118546 0.08903719 0.66314109\n",
      " 0.37911571 0.92719766 0.84107261 0.86530349 0.19918857 0.81320992\n",
      " 0.3319823  0.93641826], predicted: [0.23216783 0.22280088 0.24224412 0.22014028 0.23159674 0.21966341\n",
      " 0.22590801 0.23956539 0.2180226  0.24202085 0.23846592 0.23695588\n",
      " 0.24321207 0.2233433  0.2470156  0.23770326 0.24574783 0.24317846\n",
      " 0.24297531 0.23085603 0.23591344 0.23168634 0.23697527 0.24394588\n",
      " 0.21537398 0.21548857 0.24465896 0.24100442 0.22900538 0.24363627\n",
      " 0.23897757 0.22689563 0.21696423 0.23674296 0.24885513 0.23230325\n",
      " 0.24825887 0.21729064 0.24216759 0.24144793 0.2480764  0.23075193\n",
      " 0.2394453  0.21776333 0.22197074 0.22078119 0.24477452 0.22334427\n",
      " 0.2408336  0.21731631], n_params: 481 model_out: [0.23216783 0.22280088 0.24224412 0.22014028 0.23159674 0.21966341\n",
      " 0.22590801 0.23956539 0.2180226  0.24202085 0.23846592 0.23695588\n",
      " 0.24321207 0.2233433  0.2470156  0.23770326 0.24574783 0.24317846\n",
      " 0.24297531 0.23085603 0.23591344 0.23168634 0.23697527 0.24394588\n",
      " 0.21537398 0.21548857 0.24465896 0.24100442 0.22900538 0.24363627\n",
      " 0.23897757 0.22689563 0.21696423 0.23674296 0.24885513 0.23230325\n",
      " 0.24825887 0.21729064 0.24216759 0.24144793 0.2480764  0.23075193\n",
      " 0.2394453  0.21776333 0.22197074 0.22078119 0.24477452 0.22334427\n",
      " 0.2408336  0.21731631]\n",
      "\n",
      "epoch: 3100 SSE loss: 0.049717950820922854, l0 penalty: 7.825245361328125 total loss: 2.8771598091125488\n",
      "accuracy: 0.0, actual: [0.13507748 0.42215434 0.79111004 0.62766772 0.13890101 0.63945031\n",
      " 0.41620624 0.04227835 0.0925309  0.80190836 0.7529283  0.36361436\n",
      " 0.10839411 0.82086199 0.77409374 0.1783785  0.4618908  0.90599006\n",
      " 0.9597995  0.93778095 0.47674661 0.0978364  0.43376234 0.68679998\n",
      " 0.13408505 0.82192124 0.63180613 0.84871649 0.03450416 0.69906078\n",
      " 0.68608669 0.20116814 0.81753349 0.47930582 0.48353591 0.02097534\n",
      " 0.63899035 0.45050993 0.30961155 0.13204618 0.96628963 0.3103588\n",
      " 0.21018463 0.29612464 0.20211167 0.42479471 0.51458904 0.70793757\n",
      " 0.05434191 0.60250201], predicted: [0.23834226 0.22952907 0.21528932 0.223111   0.23822339 0.22273561\n",
      " 0.22970933 0.2412404  0.23966806 0.21474238 0.21723115 0.23130748\n",
      " 0.23917316 0.21378493 0.21615317 0.2369982  0.22832735 0.2095229\n",
      " 0.20686121 0.20794736 0.22787923 0.23950246 0.22917755 0.2205652\n",
      " 0.23837313 0.21373151 0.22297911 0.21238346 0.2414843  0.21998468\n",
      " 0.22059898 0.23629288 0.21395288 0.2278021  0.22767463 0.24190912\n",
      " 0.22275028 0.22867107 0.23295663 0.23843655 0.2065419  0.23293373\n",
      " 0.23601422 0.23336972 0.23626374 0.22944906 0.22673659 0.2195355\n",
      " 0.24086231 0.22391428], n_params: 481 model_out: [0.23834226 0.22952907 0.21528932 0.223111   0.23822339 0.22273561\n",
      " 0.22970933 0.2412404  0.23966806 0.21474238 0.21723115 0.23130748\n",
      " 0.23917316 0.21378493 0.21615317 0.2369982  0.22832735 0.2095229\n",
      " 0.20686121 0.20794736 0.22787923 0.23950246 0.22917755 0.2205652\n",
      " 0.23837313 0.21373151 0.22297911 0.21238346 0.2414843  0.21998468\n",
      " 0.22059898 0.23629288 0.21395288 0.2278021  0.22767463 0.24190912\n",
      " 0.22275028 0.22867107 0.23295663 0.23843655 0.2065419  0.23293373\n",
      " 0.23601422 0.23336972 0.23626374 0.22944906 0.22673659 0.2195355\n",
      " 0.24086231 0.22391428]\n",
      "\n",
      "epoch: 3200 SSE loss: 0.005533362627029419, l0 penalty: 7.818504638671875 total loss: 0.6675933632850647\n",
      "accuracy: 0.0, actual: [0.18349278 0.70845112 0.37286914 0.42451289 0.26573925 0.40003146\n",
      " 0.43478612 0.30395588 0.78497755 0.74431074 0.48296892 0.76078086\n",
      " 0.09778168 0.38916659 0.45166622 0.49591804 0.48881338 0.07961071\n",
      " 0.23945881 0.34006392 0.46497547 0.62681343 0.30567243 0.74182682\n",
      " 0.45845836 0.78949705 0.04813251 0.533638   0.36841198 0.82215928\n",
      " 0.04776173 0.94103703 0.82176457 0.28501051 0.32291788 0.07249291\n",
      " 0.11468367 0.76912345 0.57428868 0.99819097 0.87462969 0.91726523\n",
      " 0.62826257 0.69831766 0.94702472 0.16892404 0.57325493 0.03517991\n",
      " 0.75867445 0.45652369], predicted: [0.22874123 0.21076867 0.22273208 0.22111304 0.22611752 0.22187948\n",
      " 0.22079198 0.22490564 0.20680784 0.20891897 0.21929061 0.20806207\n",
      " 0.23149815 0.22222024 0.22026515 0.21888837 0.21910901 0.2320856\n",
      " 0.22695357 0.22376491 0.21985044 0.2145644  0.22485134 0.20904846\n",
      " 0.22005345 0.2065742  0.23310573 0.217643   0.2228722  0.20489141\n",
      " 0.23311774 0.19885294 0.2049117  0.22550584 0.22430609 0.23231602\n",
      " 0.23095264 0.20762898 0.21629596 0.19599773 0.2022095  0.20004964\n",
      " 0.21451674 0.2112572  0.19855236 0.22920822 0.21633014 0.23352642\n",
      " 0.2081715  0.22011375], n_params: 481 model_out: [0.22874123 0.21076867 0.22273208 0.22111304 0.22611752 0.22187948\n",
      " 0.22079198 0.22490564 0.20680784 0.20891897 0.21929061 0.20806207\n",
      " 0.23149815 0.22222024 0.22026515 0.21888837 0.21910901 0.2320856\n",
      " 0.22695357 0.22376491 0.21985044 0.2145644  0.22485134 0.20904846\n",
      " 0.22005345 0.2065742  0.23310573 0.217643   0.2228722  0.20489141\n",
      " 0.23311774 0.19885294 0.2049117  0.22550584 0.22430609 0.23231602\n",
      " 0.23095264 0.20762898 0.21629596 0.19599773 0.2022095  0.20004964\n",
      " 0.21451674 0.2112572  0.19855236 0.22920822 0.21633014 0.23352642\n",
      " 0.2081715  0.22011375]\n",
      "\n",
      "epoch: 3300 SSE loss: 0.049291739463806154, l0 penalty: 7.811595458984375 total loss: 2.8551667461395263\n",
      "accuracy: 0.0, actual: [0.13733375 0.41959264 0.82362359 0.8130088  0.40342228 0.12841912\n",
      " 0.93187418 0.84491791 0.54794881 0.81733844 0.90418554 0.61799531\n",
      " 0.2075585  0.56863619 0.91805436 0.95674472 0.10329594 0.57273335\n",
      " 0.00668725 0.82473856 0.14287    0.07919643 0.11296643 0.59406772\n",
      " 0.36330313 0.80692602 0.92543564 0.61771089 0.18083972 0.18944432\n",
      " 0.74942243 0.92709509 0.68465941 0.36052978 0.80393648 0.8043856\n",
      " 0.21579889 0.36529433 0.51605288 0.01644406 0.82227221 0.55692593\n",
      " 0.34796294 0.27229195 0.00488824 0.96543816 0.65384844 0.14878415\n",
      " 0.96541482 0.69776628], predicted: [0.22284918 0.21364515 0.19671622 0.19727062 0.21416485 0.22314438\n",
      " 0.19112931 0.1956075  0.20937355 0.19704433 0.1925467  0.20700034\n",
      " 0.2205331  0.20867056 0.19183576 0.189863   0.22397798 0.20853157\n",
      " 0.22720398 0.19665802 0.22266589 0.22477964 0.22365683 0.20780878\n",
      " 0.21545829 0.19758886 0.19145821 0.20700993 0.22141223 0.22112885\n",
      " 0.20061648 0.19137336 0.20386992 0.21554793 0.1977454  0.1977219\n",
      " 0.22026242 0.21539398 0.21046078 0.22687665 0.19678673 0.20906825\n",
      " 0.21595433 0.21841347 0.22726433 0.18942185 0.20539042 0.22247031\n",
      " 0.18942307 0.20322564], n_params: 481 model_out: [0.22284918 0.21364515 0.19671622 0.19727062 0.21416485 0.22314438\n",
      " 0.19112931 0.1956075  0.20937355 0.19704433 0.1925467  0.20700034\n",
      " 0.2205331  0.20867056 0.19183576 0.189863   0.22397798 0.20853157\n",
      " 0.22720398 0.19665802 0.22266589 0.22477964 0.22365683 0.20780878\n",
      " 0.21545829 0.19758886 0.19145821 0.20700993 0.22141223 0.22112885\n",
      " 0.20061648 0.19137336 0.20386992 0.21554793 0.1977454  0.1977219\n",
      " 0.22026242 0.21539398 0.21046078 0.22687665 0.19678673 0.20906825\n",
      " 0.21595433 0.21841347 0.22726433 0.18942185 0.20539042 0.22247031\n",
      " 0.18942307 0.20322564]\n",
      "\n",
      "epoch: 3400 SSE loss: 0.03316680908203125, l0 penalty: 7.804475708007812 total loss: 2.048564239501953\n",
      "accuracy: 0.0, actual: [2.00662677e-04 1.01984156e-01 4.04095180e-03 7.13984317e-01\n",
      " 6.13902274e-01 2.80699432e-01 8.98132163e-01 4.54690165e-01\n",
      " 5.06456671e-02 8.83722434e-01 1.36194048e-01 8.45556082e-01\n",
      " 7.68360663e-01 7.83579249e-01 2.17084929e-01 1.05775995e-01\n",
      " 5.55401418e-01 2.15501501e-01 7.68217221e-01 8.09967725e-01\n",
      " 8.59834292e-01 3.50293661e-01 5.38552211e-01 3.70270769e-02\n",
      " 5.60161417e-01 7.41471492e-01 7.53343057e-01 7.11229292e-01\n",
      " 1.66543234e-01 4.50362518e-01 6.90174256e-01 7.98021044e-01\n",
      " 2.99779743e-01 8.20133380e-01 5.51280977e-01 8.17489296e-02\n",
      " 8.95301324e-02 2.15138524e-01 8.24803126e-01 9.67403501e-01\n",
      " 2.49660071e-01 8.02369049e-01 3.23237734e-02 8.88374481e-02\n",
      " 5.18466768e-01 5.41922551e-01 2.10493683e-01 9.18904628e-01\n",
      " 9.66604652e-01 9.20515611e-01], predicted: [0.2207871  0.21730015 0.2206548  0.19510439 0.19998209 0.21127433\n",
      " 0.1854663  0.20552619 0.21905395 0.18621668 0.21613716 0.18821558\n",
      " 0.19230884 0.1914965  0.21340515 0.21717103 0.20200749 0.21345831\n",
      " 0.19231652 0.19009426 0.18746588 0.2089611  0.20259367 0.2195209\n",
      " 0.2018421  0.1937438  0.19311297 0.19524121 0.2151092  0.20566773\n",
      " 0.19628882 0.19072814 0.21063825 0.18955615 0.20215072 0.21799023\n",
      " 0.21772468 0.21347058 0.18930942 0.18189143 0.21231207 0.19049726\n",
      " 0.21968232 0.21774828 0.20329407 0.20247631 0.21362679 0.18438862\n",
      " 0.18193235 0.18430525], n_params: 481 model_out: [0.2207871  0.21730015 0.2206548  0.19510439 0.19998209 0.21127433\n",
      " 0.1854663  0.20552619 0.21905395 0.18621668 0.21613716 0.18821558\n",
      " 0.19230884 0.1914965  0.21340515 0.21717103 0.20200749 0.21345831\n",
      " 0.19231652 0.19009426 0.18746588 0.2089611  0.20259367 0.2195209\n",
      " 0.2018421  0.1937438  0.19311297 0.19524121 0.2151092  0.20566773\n",
      " 0.19628882 0.19072814 0.21063825 0.18955615 0.20215072 0.21799023\n",
      " 0.21772468 0.21347058 0.18930942 0.18189143 0.21231207 0.19049726\n",
      " 0.21968232 0.21774828 0.20329407 0.20247631 0.21362679 0.18438862\n",
      " 0.18193235 0.18430525]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 3500 SSE loss: 0.029899399280548095, l0 penalty: 7.797201538085938 total loss: 1.8848300409317016\n",
      "accuracy: 0.0, actual: [0.93656379 0.29330629 0.71696113 0.97770735 0.46248868 0.95647445\n",
      " 0.6050101  0.22903965 0.94625056 0.85270814 0.11594969 0.57132807\n",
      " 0.03979628 0.49921246 0.69562301 0.17441155 0.23401466 0.01122773\n",
      " 0.70659574 0.78306599 0.93497557 0.5777703  0.28601512 0.31964301\n",
      " 0.31330001 0.99867422 0.50271547 0.69948505 0.19834866 0.67062492\n",
      " 0.06411956 0.32203181 0.24092778 0.25941079 0.25054223 0.44311414\n",
      " 0.58788874 0.54324192 0.51296574 0.23324817 0.77078055 0.28826467\n",
      " 0.00248217 0.69585547 0.23473468 0.87028814 0.90305784 0.22837777\n",
      " 0.75358128 0.01285757], predicted: [0.17650412 0.2042409  0.18799186 0.17437913 0.1985196  0.17547321\n",
      " 0.19347425 0.20642999 0.17600197 0.18089803 0.21032421 0.19465776\n",
      " 0.21297677 0.19721018 0.18906192 0.20830442 0.2062599  0.21397811\n",
      " 0.18851107 0.18461159 0.17658655 0.19443098 0.2044884  0.2033488\n",
      " 0.20356339 0.17330006 0.19708557 0.18886787 0.20748153 0.19032145\n",
      " 0.21212691 0.20326802 0.20602375 0.20539331 0.20569561 0.19920516\n",
      " 0.19407518 0.19564883 0.19672143 0.20628615 0.18527277 0.20441201\n",
      " 0.21428534 0.18905023 0.2062353  0.17996985 0.17824964 0.20645265\n",
      " 0.18616627 0.21392085], n_params: 481 model_out: [0.17650412 0.2042409  0.18799186 0.17437913 0.1985196  0.17547321\n",
      " 0.19347425 0.20642999 0.17600197 0.18089803 0.21032421 0.19465776\n",
      " 0.21297677 0.19721018 0.18906192 0.20830442 0.2062599  0.21397811\n",
      " 0.18851107 0.18461159 0.17658655 0.19443098 0.2044884  0.2033488\n",
      " 0.20356339 0.17330006 0.19708557 0.18886787 0.20748153 0.19032145\n",
      " 0.21212691 0.20326802 0.20602375 0.20539331 0.20569561 0.19920516\n",
      " 0.19407518 0.19564883 0.19672143 0.20628615 0.18527277 0.20441201\n",
      " 0.21428534 0.18905023 0.2062353  0.17996985 0.17824964 0.20645265\n",
      " 0.18616627 0.21392085]\n",
      "\n",
      "epoch: 3600 SSE loss: 0.009635251760482789, l0 penalty: 7.789859619140625 total loss: 0.8712555689811707\n",
      "accuracy: 0.0, actual: [0.96640266 0.97460166 0.13041766 0.51013154 0.1138403  0.69669044\n",
      " 0.47942284 0.08003394 0.05753852 0.95329867 0.17463638 0.61935838\n",
      " 0.73656151 0.64236305 0.77758441 0.58308743 0.05330484 0.00746719\n",
      " 0.62382451 0.22202221 0.04071346 0.37415396 0.7797911  0.69935387\n",
      " 0.93522745 0.91329257 0.42033678 0.06927181 0.84093899 0.45423756\n",
      " 0.46888852 0.5076206  0.81485208 0.04595186 0.80313049 0.46348752\n",
      " 0.93450995 0.14389768 0.35012126 0.90064931 0.86041538 0.68166079\n",
      " 0.66269863 0.83389764 0.49775905 0.68085505 0.15548978 0.72338156\n",
      " 0.55933849 0.37760303], predicted: [0.16795553 0.1675317  0.20327014 0.19001442 0.20385426 0.18202604\n",
      " 0.1911229  0.2050495  0.20584765 0.16863467 0.20171797 0.18597175\n",
      " 0.18001729 0.18479115 0.17795414 0.18740062 0.20599815 0.20763254\n",
      " 0.18574208 0.20006453 0.20644614 0.19482487 0.17783463 0.1818913\n",
      " 0.16957492 0.17072171 0.19325499 0.2054311  0.17454828 0.19203573\n",
      " 0.19150433 0.19010484 0.1759444  0.20625965 0.17657457 0.19170009\n",
      " 0.16961232 0.20279603 0.19564562 0.17138554 0.17351161 0.18278776\n",
      " 0.18375234 0.17492425 0.19046043 0.18282866 0.20238896 0.18067934\n",
      " 0.18824843 0.1947073 ], n_params: 481 model_out: [0.16795553 0.1675317  0.20327014 0.19001442 0.20385426 0.18202604\n",
      " 0.1911229  0.2050495  0.20584765 0.16863467 0.20171797 0.18597175\n",
      " 0.18001729 0.18479115 0.17795414 0.18740062 0.20599815 0.20763254\n",
      " 0.18574208 0.20006453 0.20644614 0.19482487 0.17783463 0.1818913\n",
      " 0.16957492 0.17072171 0.19325499 0.2054311  0.17454828 0.19203573\n",
      " 0.19150433 0.19010484 0.1759444  0.20625965 0.17657457 0.19170009\n",
      " 0.16961232 0.20279603 0.19564562 0.17138554 0.17351161 0.18278776\n",
      " 0.18375234 0.17492425 0.19046043 0.18282866 0.20238896 0.18067934\n",
      " 0.18824843 0.1947073 ]\n",
      "\n",
      "epoch: 3700 SSE loss: 0.009915733337402343, l0 penalty: 7.7821044921875 total loss: 0.8848918914794922\n",
      "accuracy: 0.0, actual: [0.33381038 0.29088392 0.65574438 0.9693528  0.42608455 0.04611018\n",
      " 0.38518418 0.97866201 0.92247747 0.50047735 0.05488655 0.9634503\n",
      " 0.96815475 0.20160807 0.92400903 0.52732191 0.18393034 0.97729779\n",
      " 0.5314058  0.2579166  0.23839411 0.73281807 0.00273167 0.14351754\n",
      " 0.01802252 0.05574832 0.95869588 0.82222897 0.52261128 0.1056877\n",
      " 0.71851614 0.85452676 0.51634248 0.82558169 0.56370003 0.04482644\n",
      " 0.66436811 0.30077121 0.19045634 0.95972767 0.98367106 0.61136052\n",
      " 0.21242494 0.40306055 0.86310111 0.3591956  0.71332648 0.91680135\n",
      " 0.25731539 0.51436504], predicted: [0.19162044 0.19310893 0.1793412  0.16301762 0.1884339  0.2017645\n",
      " 0.18985058 0.16251916 0.16546029 0.18571481 0.20144922 0.16332358\n",
      " 0.16307968 0.19623274 0.16538003 0.18474108 0.1968558  0.16259265\n",
      " 0.1845933  0.19425806 0.19494094 0.17542587 0.20332833 0.19828576\n",
      " 0.20277604 0.20141827 0.16357036 0.1707826  0.18491168 0.19963138\n",
      " 0.1761473  0.16905318 0.18513888 0.17060243 0.18342791 0.20181064\n",
      " 0.17889972 0.19276533 0.1966256  0.1635168  0.16224958 0.18162668\n",
      " 0.19585219 0.18923765 0.16859639 0.19074434 0.17640966 0.16575803\n",
      " 0.19427904 0.1852106 ], n_params: 481 model_out: [0.19162044 0.19310893 0.1793412  0.16301762 0.1884339  0.2017645\n",
      " 0.18985058 0.16251916 0.16546029 0.18571481 0.20144922 0.16332358\n",
      " 0.16307968 0.19623274 0.16538003 0.18474108 0.1968558  0.16259265\n",
      " 0.1845933  0.19425806 0.19494094 0.17542587 0.20332833 0.19828576\n",
      " 0.20277604 0.20141827 0.16357036 0.1707826  0.18491168 0.19963138\n",
      " 0.1761473  0.16905318 0.18513888 0.17060243 0.18342791 0.20181064\n",
      " 0.17889972 0.19276533 0.1966256  0.1635168  0.16224958 0.18162668\n",
      " 0.19585219 0.18923765 0.16859639 0.19074434 0.17640966 0.16575803\n",
      " 0.19427904 0.1852106 ]\n",
      "\n",
      "epoch: 3800 SSE loss: 0.019281175136566162, l0 penalty: 7.7742852783203125 total loss: 1.3527730207443238\n",
      "accuracy: 0.0, actual: [0.5028155  0.79340351 0.96515952 0.42043626 0.58573385 0.28638437\n",
      " 0.47940074 0.92705539 0.99863699 0.09429493 0.27270439 0.8507123\n",
      " 0.07047209 0.55239148 0.96476684 0.64350152 0.80691093 0.00775073\n",
      " 0.67065684 0.62913193 0.50364114 0.66423449 0.1274596  0.38949494\n",
      " 0.86465072 0.0614586  0.56317641 0.26691623 0.06032953 0.67731736\n",
      " 0.91888593 0.25715161 0.78949754 0.500947   0.62334612 0.67945708\n",
      " 0.36889397 0.05049641 0.84219068 0.67470563 0.41326924 0.11079848\n",
      " 0.39983737 0.76620894 0.22786323 0.40313879 0.62728755 0.71805637\n",
      " 0.00693931 0.45237302], predicted: [0.18084636 0.16746455 0.15834017 0.18388015 0.17783232 0.18856499\n",
      " 0.18170469 0.16033357 0.15653783 0.19539793 0.18904547 0.16437629\n",
      " 0.19625832 0.17903957 0.1583614  0.17507169 0.16673249 0.19853716\n",
      " 0.17367664 0.17581344 0.1808162  0.17400578 0.19420496 0.18497346\n",
      " 0.1636321  0.19658457 0.17864835 0.18924907 0.19662547 0.17333578\n",
      " 0.1607623  0.1895929  0.16767469 0.18091474 0.17611282 0.17322645\n",
      " 0.18568681 0.19698195 0.16483259 0.17346942 0.18414593 0.19480363\n",
      " 0.18461616 0.16883768 0.19062702 0.18450223 0.17590883 0.17126267\n",
      " 0.19856678 0.18269937], n_params: 481 model_out: [0.18084636 0.16746455 0.15834017 0.18388015 0.17783232 0.18856499\n",
      " 0.18170469 0.16033357 0.15653783 0.19539793 0.18904547 0.16437629\n",
      " 0.19625832 0.17903957 0.1583614  0.17507169 0.16673249 0.19853716\n",
      " 0.17367664 0.17581344 0.1808162  0.17400578 0.19420496 0.18497346\n",
      " 0.1636321  0.19658457 0.17864835 0.18924907 0.19662547 0.17333578\n",
      " 0.1607623  0.1895929  0.16767469 0.18091474 0.17611282 0.17322645\n",
      " 0.18568681 0.19698195 0.16483259 0.17346942 0.18414593 0.19480363\n",
      " 0.18461616 0.16883768 0.19062702 0.18450223 0.17590883 0.17126267\n",
      " 0.19856678 0.18269937]\n",
      "\n",
      "epoch: 3900 SSE loss: 0.005366721153259277, l0 penalty: 7.766409301757813 total loss: 0.6566565227508545\n",
      "accuracy: 0.0, actual: [6.91806974e-01 9.15699775e-01 4.62604355e-01 3.32001528e-01\n",
      " 1.52247573e-01 8.88174199e-01 1.43886052e-02 5.07272605e-01\n",
      " 1.42422815e-01 1.31870882e-01 5.77950832e-01 8.79617550e-02\n",
      " 7.19435132e-05 1.24149141e-01 6.40232182e-01 9.20797152e-01\n",
      " 1.97795999e-01 9.33266760e-01 1.03802731e-01 8.31897527e-01\n",
      " 4.26356247e-01 6.12459458e-02 1.03605025e-01 2.97110087e-01\n",
      " 7.15178272e-01 2.01696226e-01 2.97510111e-01 6.54412717e-01\n",
      " 4.94732108e-01 9.58704682e-01 2.36405023e-01 1.46022132e-01\n",
      " 2.17090230e-01 5.04067167e-01 8.44416959e-01 1.69924228e-01\n",
      " 6.87403927e-01 7.58131459e-01 5.73923377e-01 6.54671200e-01\n",
      " 7.58292405e-01 7.60471756e-01 9.33817363e-01 4.60685921e-01\n",
      " 3.28757964e-02 3.61369076e-01 7.85191662e-01 2.88586940e-01\n",
      " 7.48881557e-01 1.68929892e-01], predicted: [0.16794145 0.15629774 0.17777823 0.18247521 0.18886206 0.1577518\n",
      " 0.19387555 0.17612924 0.18921605 0.18959679 0.17354465 0.19118744\n",
      " 0.19440195 0.18987577 0.17059156 0.15602969 0.18722759 0.15537553\n",
      " 0.19061244 0.16075873 0.17912528 0.19216023 0.19061956 0.18370168\n",
      " 0.16675144 0.18708815 0.18368757 0.16985963 0.176591   0.15403816\n",
      " 0.18585072 0.18908629 0.18653855 0.17624721 0.1600858  0.18822645\n",
      " 0.16816644 0.16458191 0.17369112 0.16984633 0.16457382 0.16446434\n",
      " 0.15534669 0.17784935 0.1931974  0.18144782 0.16322678 0.18400222\n",
      " 0.1650472  0.18826216], n_params: 481 model_out: [0.16794145 0.15629774 0.17777823 0.18247521 0.18886206 0.1577518\n",
      " 0.19387555 0.17612924 0.18921605 0.18959679 0.17354465 0.19118744\n",
      " 0.19440195 0.18987577 0.17059156 0.15602969 0.18722759 0.15537553\n",
      " 0.19061244 0.16075873 0.17912528 0.19216023 0.19061956 0.18370168\n",
      " 0.16675144 0.18708815 0.18368757 0.16985963 0.176591   0.15403816\n",
      " 0.18585072 0.18908629 0.18653855 0.17624721 0.1600858  0.18822645\n",
      " 0.16816644 0.16458191 0.17369112 0.16984633 0.16457382 0.16446434\n",
      " 0.15534669 0.17784935 0.1931974  0.18144782 0.16322678 0.18400222\n",
      " 0.1650472  0.18826216]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 4000 SSE loss: 0.006549602150917053, l0 penalty: 7.758446044921875 total loss: 0.7154024097919465\n",
      "accuracy: 0.0, actual: [0.21776986 0.58724972 0.9876133  0.95086705 0.34297149 0.39389324\n",
      " 0.58573127 0.31384096 0.8532363  0.53031352 0.73691596 0.23933497\n",
      " 0.81544938 0.41063763 0.37707666 0.72059189 0.69629163 0.37351208\n",
      " 0.8857305  0.76544058 0.43635873 0.96868552 0.92976244 0.15911103\n",
      " 0.72552475 0.5989313  0.14331981 0.06272644 0.35662631 0.71137245\n",
      " 0.3667841  0.23897153 0.33319889 0.53158815 0.56552545 0.25363734\n",
      " 0.33481974 0.57202368 0.33461279 0.73643939 0.28074505 0.57774971\n",
      " 0.68363098 0.78815434 0.86252649 0.68589606 0.40991839 0.0750447\n",
      " 0.57870191 0.33163897], predicted: [0.18179825 0.16838315 0.14760847 0.14959009 0.17734429 0.17555745\n",
      " 0.16843858 0.17837289 0.15474801 0.17047133 0.16075277 0.18102491\n",
      " 0.15678003 0.17492743 0.17614596 0.16157904 0.16281539 0.17627093\n",
      " 0.15301783 0.15931714 0.17396203 0.14862649 0.15069874 0.1839147\n",
      " 0.16132899 0.16784543 0.18448775 0.18743375 0.17686374 0.1620472\n",
      " 0.17650694 0.18103792 0.17768882 0.17042434 0.16917747 0.18051347\n",
      " 0.17763165 0.16893959 0.17763895 0.16077682 0.17954716 0.16873014\n",
      " 0.16346255 0.15818141 0.15425174 0.16334662 0.1749545  0.18698114\n",
      " 0.16869533 0.17774391], n_params: 481 model_out: [0.18179825 0.16838315 0.14760847 0.14959009 0.17734429 0.17555745\n",
      " 0.16843858 0.17837289 0.15474801 0.17047133 0.16075277 0.18102491\n",
      " 0.15678003 0.17492743 0.17614596 0.16157904 0.16281539 0.17627093\n",
      " 0.15301783 0.15931714 0.17396203 0.14862649 0.15069874 0.1839147\n",
      " 0.16132899 0.16784543 0.18448775 0.18743375 0.17686374 0.1620472\n",
      " 0.17650694 0.18103792 0.17768882 0.17042434 0.16917747 0.18051347\n",
      " 0.17763165 0.16893959 0.17763895 0.16077682 0.17954716 0.16873014\n",
      " 0.16346255 0.15818141 0.15425174 0.16334662 0.1749545  0.18698114\n",
      " 0.16869533 0.17774391]\n",
      "\n",
      "epoch: 4100 SSE loss: 0.005491257905960083, l0 penalty: 7.750284423828125 total loss: 0.6620771164894104\n",
      "accuracy: 0.0, actual: [0.04403379 0.36062995 0.71338395 0.61532074 0.64586873 0.57539997\n",
      " 0.26713747 0.87097533 0.18153676 0.50510687 0.07423506 0.46825418\n",
      " 0.73148245 0.18737261 0.79037497 0.40054227 0.51333053 0.41013641\n",
      " 0.04569282 0.47143589 0.05907263 0.053456   0.61839491 0.15973492\n",
      " 0.4044141  0.46568385 0.634926   0.23608252 0.88790954 0.60472276\n",
      " 0.93732714 0.47030397 0.83982304 0.81249638 0.57258164 0.97472128\n",
      " 0.10158922 0.39689898 0.72618822 0.4637265  0.5912195  0.38431397\n",
      " 0.63207348 0.31686856 0.87422661 0.92484924 0.34221352 0.44850366\n",
      " 0.46666134 0.54117701], predicted: [0.18393488 0.17241372 0.15743497 0.16249472 0.16090465 0.16441731\n",
      " 0.17575534 0.14931    0.17885935 0.16702525 0.18281065 0.1684057\n",
      " 0.15651526 0.17864636 0.15355286 0.17096575 0.16671845 0.17060114\n",
      " 0.18387301 0.16828614 0.18337439 0.1835836  0.16233413 0.17965671\n",
      " 0.17081851 0.16850232 0.1614728  0.1768765  0.14841035 0.16304934\n",
      " 0.1458103  0.16832864 0.15097676 0.1524514  0.16452123 0.14378548\n",
      " 0.18179692 0.17110436 0.15678385 0.16857591 0.16375813 0.17157525\n",
      " 0.16162115 0.17397153 0.14913695 0.14646342 0.17306797 0.16914926\n",
      " 0.16846555 0.1656829 ], n_params: 481 model_out: [0.18393488 0.17241372 0.15743497 0.16249472 0.16090465 0.16441731\n",
      " 0.17575534 0.14931    0.17885935 0.16702525 0.18281065 0.1684057\n",
      " 0.15651526 0.17864636 0.15355286 0.17096575 0.16671845 0.17060114\n",
      " 0.18387301 0.16828614 0.18337439 0.1835836  0.16233413 0.17965671\n",
      " 0.17081851 0.16850232 0.1614728  0.1768765  0.14841035 0.16304934\n",
      " 0.1458103  0.16832864 0.15097676 0.1524514  0.16452123 0.14378548\n",
      " 0.18179692 0.17110436 0.15678385 0.16857591 0.16375813 0.17157525\n",
      " 0.16162115 0.17397153 0.14913695 0.14646342 0.17306797 0.16914926\n",
      " 0.16846555 0.1656829 ]\n",
      "\n",
      "epoch: 4200 SSE loss: 0.0075031864643096925, l0 penalty: 7.742044677734375 total loss: 0.7622615571022033\n",
      "accuracy: 0.0, actual: [0.29057311 0.76865617 0.05097391 0.67987166 0.2222463  0.2747929\n",
      " 0.67791467 0.92202904 0.17873352 0.94132591 0.89352535 0.65429674\n",
      " 0.45139687 0.35571416 0.10578924 0.777715   0.44717802 0.30016548\n",
      " 0.9712423  0.94401122 0.61316907 0.83502928 0.22380554 0.23496924\n",
      " 0.10114675 0.82735781 0.43655231 0.58277473 0.63607867 0.01926596\n",
      " 0.95194154 0.60798074 0.77475399 0.6831562  0.26557879 0.99017275\n",
      " 0.06797536 0.90664799 0.70740031 0.46608361 0.18111142 0.3564659\n",
      " 0.82314454 0.3009326  0.46901283 0.90356154 0.23539366 0.40262266\n",
      " 0.1110789  0.57452126], predicted: [0.17061624 0.15025048 0.17942958 0.15475312 0.17309394 0.17118594\n",
      " 0.1548536  0.142273   0.17468658 0.141244   0.14377014 0.15607043\n",
      " 0.16468704 0.1682804  0.17738236 0.14979719 0.16484687 0.17027067\n",
      " 0.1396296  0.14109844 0.15820797 0.14688362 0.17303708 0.17263043\n",
      " 0.17755504 0.1472961  0.16524999 0.15977165 0.15701437 0.18062216\n",
      " 0.14066938 0.15847932 0.14994524 0.1545846  0.17151934 0.13861607\n",
      " 0.17879264 0.14307925 0.15334536 0.1641316  0.17459926 0.16825356\n",
      " 0.14752302 0.17024305 0.16402097 0.14324151 0.17261498 0.16654256\n",
      " 0.17718576 0.16007693], n_params: 481 model_out: [0.17061624 0.15025048 0.17942958 0.15475312 0.17309394 0.17118594\n",
      " 0.1548536  0.142273   0.17468658 0.141244   0.14377014 0.15607043\n",
      " 0.16468704 0.1682804  0.17738236 0.14979719 0.16484687 0.17027067\n",
      " 0.1396296  0.14109844 0.15820797 0.14688362 0.17303708 0.17263043\n",
      " 0.17755504 0.1472961  0.16524999 0.15977165 0.15701437 0.18062216\n",
      " 0.14066938 0.15847932 0.14994524 0.1545846  0.17151934 0.13861607\n",
      " 0.17879264 0.14307925 0.15334536 0.1641316  0.17459926 0.16825356\n",
      " 0.14752302 0.17024305 0.16402097 0.14324151 0.17261498 0.16654256\n",
      " 0.17718576 0.16007693]\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "alpha = 1\n",
    "enable_gpu = True\n",
    "l0_reg = 0.001\n",
    "\n",
    "# for seed in range(args.n_seeds):\n",
    "utils.common.set_global_seeds(seed)\n",
    "\n",
    "model = L0FCN(input_bins=1,\n",
    "              output_bins=1,\n",
    "              fc_config=[20]*2,\n",
    "              enable_gpu=True,\n",
    "              test_mode=False)\n",
    "\n",
    "if enable_gpu:\n",
    "    model = model.cuda()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(),\n",
    "                       lr=1e-4,\n",
    "                       weight_decay=0)\n",
    "\n",
    "objective = SSE()\n",
    "\n",
    "prev_loss = 0\n",
    "epoch = 0\n",
    "best_model = None\n",
    "best_acc = 100\n",
    "best_nparams = 0\n",
    "\n",
    "while True:\n",
    "    X_train = np.random.rand(50)\n",
    "    y_train = np.array(list(map(lambda x: logistic_map(x, alpha), X_train)))\n",
    "\n",
    "    X_train = X_train.reshape((-1, 1))\n",
    "    y_train = y_train.reshape((-1, 1))\n",
    "\n",
    "    model.train()\n",
    "    model, (log_loss, penalty), model_out = model_forward_fcn(X_train,\n",
    "                                                              y_train,\n",
    "                                                              model,\n",
    "                                                              objective,\n",
    "                                                              optimizer,\n",
    "                                                              l0_reg,\n",
    "                                                              enable_gpu=enable_gpu)\n",
    "    total_loss = (log_loss + l0_reg * penalty)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "\n",
    "    _, _, model_out = model_forward_fcn(X_train,\n",
    "                                        y_train,\n",
    "                                        model,\n",
    "                                        objective,\n",
    "                                        optimizer,\n",
    "                                        l0_reg,\n",
    "                                        enable_gpu=enable_gpu,\n",
    "                                        backward=False)\n",
    "#     predictions = (np.array(model_out) > 0.5).astype(int)\n",
    "    predictions = np.array(model_out).flatten()\n",
    "    actual = y_train.flatten()\n",
    "    # print(actual == predictions)\n",
    "    accuracy = np.sum(actual == predictions) / len(actual)\n",
    "    model_nparams = model.get_l0_norm()\n",
    "\n",
    "    # if accuracy > best_acc or (accuracy == best_acc and best_nparams > model_nparams):\n",
    "    if log_loss <= best_acc and not (np.isnan(log_loss) or np.isnan(penalty)):\n",
    "        best_model = copy.deepcopy(model.state_dict())\n",
    "        best_acc = log_loss\n",
    "        best_nparams = model_nparams\n",
    "    div = X_train.shape[0]\n",
    "    # print diagnostics\n",
    "    if epoch % 100 == 0:\n",
    "        model_out = np.array(model_out).flatten()\n",
    "        print(\"\")\n",
    "        print(\"epoch: {} SSE loss: {}, l0 penalty: {} total loss: {}\".format(epoch,\n",
    "                                                                              log_loss / div,\n",
    "                                                                              penalty / div,\n",
    "                                                                              total_loss))\n",
    "        print(\"accuracy: {}, actual: {}, predicted: {}, n_params: {} model_out: {}\".format(accuracy,\n",
    "                                                                                                 X_train.flatten(),\n",
    "                                                                                                 predictions,\n",
    "                                                                                                 model.get_l0_norm(),\n",
    "                                                                                                 model_out))\n",
    "\n",
    "    if np.abs(total_loss - prev_loss) <= 1e-9:\n",
    "        print(\"Training converged: {}\".format(np.abs(total_loss - prev_loss)))\n",
    "        break\n",
    "\n",
    "    prev_loss = total_loss\n",
    "    epoch += 1\n",
    "\n",
    "    if np.isnan(log_loss) or np.isnan(penalty):\n",
    "        print(\"NaN detected\")\n",
    "        break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = L0FCN(input_bins=1,\n",
    "                  output_bins=1,\n",
    "                  fc_config=[20]*2,\n",
    "                  enable_gpu=True,\n",
    "                  test_mode=False)\n",
    "model_test.load_state_dict(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test.get_l0_norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = model_test.cuda()\n",
    "\n",
    "x = np.arange(0, 1, 0.01)\n",
    "y = list(map(lambda val: logistic_map(val, alpha), x))\n",
    "y_pred = None\n",
    "k = 1\n",
    "for i in range(k):\n",
    "    y_pred_k = []\n",
    "    for x_val in x:\n",
    "        x_val = torch.FloatTensor([x_val]).cuda()\n",
    "        out, _ = model_test.forward(x_val)\n",
    "        out = torch.clamp(out, -8, 8)\n",
    "        out = F.sigmoid(out)\n",
    "        y_pred_k.append(out.data.cpu().numpy()[0])\n",
    "    \n",
    "    if y_pred is None:\n",
    "        y_pred = np.array(y_pred_k)\n",
    "    else:\n",
    "        y_pred += np.array(y_pred_k)\n",
    "\n",
    "y_pred = y_pred/k\n",
    "plot_options = dict(width=900,\n",
    "                    plot_height=450,\n",
    "                    tools='pan,wheel_zoom,reset,save')\n",
    "\n",
    "plot = figure(**plot_options)\n",
    "plot.line(x,\n",
    "          y)\n",
    "plot.line(x,\n",
    "          y_pred,\n",
    "         line_color=\"orange\")\n",
    "plot.x(X_train.flatten(),\n",
    "       y_train.flatten())\n",
    "\n",
    "plot.xaxis.axis_label = 'x'\n",
    "plot.yaxis.axis_label = 'f(x)'\n",
    "\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_pred = []\n",
    "series_pred_in = []\n",
    "series_actual = []\n",
    "lambda_series_pred = []\n",
    "lambda_series_actual = []\n",
    "x_t_m = 0.7\n",
    "x_t_a = x_t_m\n",
    "x_t_i = x_t_m\n",
    "n_points = 500\n",
    "\n",
    "step = 0\n",
    "tot_steps = 5\n",
    "\n",
    "for i in range(n_points):\n",
    "    x_val = torch.FloatTensor([x_t_m]).cuda()\n",
    "    out, _ = model_test.forward(x_val)\n",
    "    out = torch.clamp(out, -8, 8)\n",
    "    out = F.sigmoid(out)\n",
    "    lambda_series_pred.append(out.data.cpu().numpy()[0]/(x_t_m*(1-x_t_m)))\n",
    "    x_t_m = out.data.cpu().numpy()[0]\n",
    "    series_pred.append(x_t_m)\n",
    "    \n",
    "    if step >= tot_steps:\n",
    "        x_t_i = x_t_a\n",
    "        step = 0\n",
    "    \n",
    "    x_val = torch.FloatTensor([x_t_i]).cuda()\n",
    "    out, _ = model_test.forward(x_val)\n",
    "    out = torch.clamp(out, -8, 8)\n",
    "    out = F.sigmoid(out)\n",
    "    x_t_i = out.data.cpu().numpy()[0]\n",
    "    series_pred_in.append(x_t_i)\n",
    "    step += 1\n",
    "    \n",
    "    lambda_series_actual.append(logistic_map(x_t_a, alpha=alpha)/(x_t_a*(1-x_t_a)))\n",
    "    x_t_a = logistic_map(x_t_a, alpha=alpha)\n",
    "    series_actual.append(x_t_a)\n",
    "\n",
    "plot_options = dict(width=900,\n",
    "                    plot_height=450,\n",
    "                    tools='pan,xwheel_zoom,reset,save')\n",
    "\n",
    "plot = figure(**plot_options)\n",
    "plot.line(range(n_points),\n",
    "          series_actual)\n",
    "plot.line(range(n_points),\n",
    "          series_pred,\n",
    "          line_color=\"orange\")\n",
    "plot.line(range(n_points),\n",
    "          series_pred_in,\n",
    "          line_color=\"red\")\n",
    "\n",
    "plot.xaxis.axis_label = 'step'\n",
    "plot.yaxis.axis_label = 'f(x)'\n",
    "\n",
    "show(plot)\n",
    "\n",
    "mean_lambda_pred = [ np.mean(lambda_series_pred[:i]) \n",
    "                    for i in range(1, len(lambda_series_pred)) ]\n",
    "\n",
    "plot = figure(**plot_options)\n",
    "plot.line(range(n_points),\n",
    "          lambda_series_actual)\n",
    "plot.line(range(n_points),\n",
    "          lambda_series_pred,\n",
    "          line_color=\"orange\")\n",
    "plot.line(range(n_points),\n",
    "          mean_lambda_pred,\n",
    "          line_color=\"red\")\n",
    "\n",
    "plot.xaxis.axis_label = 'step'\n",
    "plot.yaxis.axis_label = 'lambda'\n",
    "\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = 500\n",
    "\n",
    "step = 0\n",
    "tot_steps = 10\n",
    "step_stderr = []\n",
    "\n",
    "for step in range(1, tot_steps):\n",
    "    print(step)\n",
    "    step_err = []\n",
    "    for i in range(n_points):  \n",
    "        x_t_m = series_actual[i]\n",
    "        err = []\n",
    "        for pred_step in range(step):\n",
    "            x_val = torch.FloatTensor([x_t_m]).cuda()\n",
    "            out, _ = model_test.forward(x_val)\n",
    "            out = torch.clamp(out, -8, 8)\n",
    "            out = F.sigmoid(out)\n",
    "            lambda_series_pred.append(out.data.cpu().numpy()[0]/(x_t_m*(1-x_t_m)))\n",
    "            x_t_m = out.data.cpu().numpy()[0]\n",
    "            \n",
    "            try:\n",
    "                err.append(np.abs(series_actual[i+pred_step+1] - x_t_m))\n",
    "            except IndexError:\n",
    "                break\n",
    "        step_err.append(np.mean(err))\n",
    "    step_err = np.array(step_err)\n",
    "    step_err = step_err[~np.isnan(step_err)]\n",
    "    step_stderr.append(np.mean(np.array(step_err)))\n",
    "#     print(step_err)\n",
    "#     print(step_stderr)\n",
    "            \n",
    "plot_options = dict(width=900,\n",
    "                    plot_height=450,\n",
    "                    tools='pan,xwheel_zoom,reset,save')\n",
    "\n",
    "plot = figure(**plot_options)\n",
    "plot.line(range(tot_steps),\n",
    "          step_stderr,\n",
    "         line_width=2)\n",
    "\n",
    "plot.xaxis.axis_label = 'prediction steps'\n",
    "plot.yaxis.axis_label = 'standard_error'\n",
    "\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_stderr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
